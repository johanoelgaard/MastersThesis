{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import models as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Ticker', 'Trade Close', 'Trade High', 'Trade Low',\n",
      "       'Trade Open', 'Trade Volume'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_35501/689524146.py:10: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df = df_wide.stack(level=0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "# df_wide = pd.read_csv('data/market_data.csv', header=[0,1], index_col=0)\n",
    "df_wide = pd.read_csv('data/trade_df.csv', header=[0,1], index_col=0)\n",
    "\n",
    "# Convert the index to datetime (the index holds the dates)\n",
    "df_wide.index = pd.to_datetime(df_wide.index)\n",
    "\n",
    "# Transform wide format to long format by stacking the first level of the columns (i.e., tickers)\n",
    "# After stacking, each row will correspond to a unique date and ticker.\n",
    "df = df_wide.stack(level=0).reset_index()\n",
    "\n",
    "# Rename the resulting columns to have a proper 'Date' and 'Ticker' columns.\n",
    "df.rename(columns={'Timestamp': 'Date', 'level_1': 'Ticker'}, inplace=True)\n",
    "\n",
    "# For illustration, assume that the only data variable is \"Price\".\n",
    "# If there are more variables, adjust feature selection accordingly.\n",
    "# Check resulting columns:\n",
    "print(df.columns)  # Expected: ['Date', 'Ticker', 'Price', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date            0\n",
      "Ticker          0\n",
      "Trade Close     0\n",
      "Trade High      0\n",
      "Trade Low       0\n",
      "Trade Open      0\n",
      "Trade Volume    0\n",
      "dtype: int64\n",
      "(1032572, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Trade Close</th>\n",
       "      <th>Trade High</th>\n",
       "      <th>Trade Low</th>\n",
       "      <th>Trade Open</th>\n",
       "      <th>Trade Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032674</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>AAB.CO</td>\n",
       "      <td>2719.270469</td>\n",
       "      <td>2876.151458</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>2771.564132</td>\n",
       "      <td>106.131407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032498</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>AAB.CO</td>\n",
       "      <td>2771.564132</td>\n",
       "      <td>2876.151458</td>\n",
       "      <td>2614.683143</td>\n",
       "      <td>2614.683143</td>\n",
       "      <td>18.013655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032309</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>AAB.CO</td>\n",
       "      <td>2717.178723</td>\n",
       "      <td>2771.564132</td>\n",
       "      <td>2614.683143</td>\n",
       "      <td>2614.683143</td>\n",
       "      <td>15.585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032115</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>AAB.CO</td>\n",
       "      <td>2719.270469</td>\n",
       "      <td>2719.270469</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>3.824555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031918</th>\n",
       "      <td>2001-01-08</td>\n",
       "      <td>AAB.CO</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>2666.976806</td>\n",
       "      <td>11.836998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>ZELA.CO</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>692.500000</td>\n",
       "      <td>156528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>ZELA.CO</td>\n",
       "      <td>663.000000</td>\n",
       "      <td>692.000000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>688.000000</td>\n",
       "      <td>316329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>ZELA.CO</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>664.500000</td>\n",
       "      <td>424168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>ZELA.CO</td>\n",
       "      <td>566.500000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>595943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>ZELA.CO</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>586.500000</td>\n",
       "      <td>551.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>373127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1032572 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date   Ticker  Trade Close   Trade High    Trade Low  \\\n",
       "1032674 2001-01-02   AAB.CO  2719.270469  2876.151458  2666.976806   \n",
       "1032498 2001-01-03   AAB.CO  2771.564132  2876.151458  2614.683143   \n",
       "1032309 2001-01-04   AAB.CO  2717.178723  2771.564132  2614.683143   \n",
       "1032115 2001-01-05   AAB.CO  2719.270469  2719.270469  2666.976806   \n",
       "1031918 2001-01-08   AAB.CO  2666.976806  2666.976806  2666.976806   \n",
       "...            ...      ...          ...          ...          ...   \n",
       "586     2025-02-27  ZELA.CO   695.000000   703.000000   685.000000   \n",
       "467     2025-02-28  ZELA.CO   663.000000   692.000000   657.000000   \n",
       "350     2025-03-03  ZELA.CO   610.000000   685.000000   610.000000   \n",
       "233     2025-03-04  ZELA.CO   566.500000   625.000000   557.000000   \n",
       "116     2025-03-05  ZELA.CO   555.000000   586.500000   551.000000   \n",
       "\n",
       "          Trade Open   Trade Volume  \n",
       "1032674  2771.564132     106.131407  \n",
       "1032498  2614.683143      18.013655  \n",
       "1032309  2614.683143      15.585062  \n",
       "1032115  2666.976806       3.824555  \n",
       "1031918  2666.976806      11.836998  \n",
       "...              ...            ...  \n",
       "586       692.500000  156528.000000  \n",
       "467       688.000000  316329.000000  \n",
       "350       664.500000  424168.000000  \n",
       "233       610.000000  595943.000000  \n",
       "116       574.000000  373127.000000  \n",
       "\n",
       "[1032572 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Cleaning and Sorting\n",
    "# Remove any duplicate rows and sort by ticker and date.\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True) # happens if there was one data point the first day of a given ticker but not the rest of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Momentum Features\n",
    "# We work with the \"Price\" column for momentum calculations.\n",
    "# Define momentum lookback periods (approximations: 1m ~ 21 days, 3m ~ 63, 6m ~ 126, 12m ~ 252 trading days)\n",
    "momentum_periods = {'mom_1m': 21, 'mom_3m': 63, 'mom_6m': 126, 'mom_12m': 252}\n",
    "\n",
    "# compute percentage change over each period for each ticker separately.\n",
    "for feature_name, period in momentum_periods.items():\n",
    "    df[feature_name] = df.groupby('Ticker')['Trade Close'].transform(lambda x: x.pct_change(periods=period))\n",
    "\n",
    "# drop rows where momentum features are not defined (if desired).\n",
    "df.dropna(subset=list(momentum_periods.keys()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable\n",
    "# for testing we define the target as the next-day return.\n",
    "df['target'] = df.groupby('Ticker')['Trade Close'].pct_change().shift(-1)\n",
    "df.dropna(subset=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Prepare Dataset for LSTM\n",
    "# -----------------------------\n",
    "# We create a custom dataset that groups the data by ticker so that each stock's history is a sequence.\n",
    "feature_cols = list(momentum_periods.keys())\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, group_col='Ticker'):\n",
    "        self.sequences = []\n",
    "        self.targets = []\n",
    "        # Group the data by each ticker\n",
    "        grouped = df.groupby(group_col)\n",
    "        for ticker, group in grouped:\n",
    "            group = group.sort_values('Date')\n",
    "            # Extract the momentum features and target as numpy arrays.\n",
    "            features = group[feature_cols].values  # shape: (sequence_length, num_features)\n",
    "            target = group['target'].values          # shape: (sequence_length,)\n",
    "            # Convert to torch tensors.\n",
    "            self.sequences.append(torch.tensor(features, dtype=torch.float))\n",
    "            self.targets.append(torch.tensor(target, dtype=torch.float))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "    # Define a collate function to pad sequences to the same length in a batch.\n",
    "def collate_fn(batch):\n",
    "    sequences, targets = zip(*batch)\n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True)\n",
    "    return sequences_padded, targets_padded, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        # Ensure x is on the same device as the model parameters.\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "        \n",
    "        # Pack the padded sequences so that the LSTM ignores the padding.\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (hn, cn) = self.lstm(packed)\n",
    "        \n",
    "        # Use the last hidden state of the final layer as the sequence representation.\n",
    "        out = self.fc(hn[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (MPS if available, otherwise CPU).\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set hyperparameters.\n",
    "input_dim = len(feature_cols)   # Number of momentum features.\n",
    "hidden_dim = 12\n",
    "num_layers = 2\n",
    "output_dim = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer.\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create dataset and DataLoader.\n",
    "dataset = StockDataset(df, feature_cols=feature_cols)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "# Training loop.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for sequences, targets, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move sequences to the appropriate device.\n",
    "        sequences = sequences.to(device)\n",
    "        \n",
    "        # Move each target tensor to device.\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        \n",
    "        # Forward pass: get one prediction per sequence.\n",
    "        outputs = model(sequences, lengths)\n",
    "        \n",
    "        # Use the last valid target value from each sequence.\n",
    "        last_targets = torch.stack([target[length-1] for target, length in zip(targets, lengths)])\n",
    "        \n",
    "        loss = criterion(outputs.squeeze(), last_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
