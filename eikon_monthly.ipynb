{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "import re\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Clean trade data](#toc1_1_)    \n",
    "  - [Extract valid stocks and informtion on them](#toc1_2_)    \n",
    "    - [Clean P/E, Turnover, Bid, and Ask data](#toc1_2_1_)    \n",
    "    - [P/E](#toc1_2_2_)    \n",
    "    - [Turnover](#toc1_2_3_)    \n",
    "    - [Ask](#toc1_2_4_)    \n",
    "    - [Bid](#toc1_2_5_)    \n",
    "    - [divdend](#toc1_2_6_)    \n",
    "    - [Join all dataframes](#toc1_2_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "path = '/Users/johan/Library/CloudStorage/GoogleDrive-johan.oelgaard@gmail.com/My Drive/04 Økonomi/10 Thesis/Data'\n",
    "\n",
    "# read monthly market data from eikon\n",
    "monthly = 'eikon_monthly.xlsx'\n",
    "eikon_dfs = pd.read_excel(path + '/' + monthly, sheet_name=None)\n",
    "eikon_keys = eikon_dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Clean trade data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# clean trade data\n",
    "trade_values_df = eikon_dfs['Trade Values'].iloc[:,1:]\n",
    "\n",
    "# set up multi-index for the columns\n",
    "trade_values_df.columns = pd.MultiIndex.from_arrays(trade_values_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "trade_values_df = trade_values_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "trade_values_df.set_index(trade_values_df.columns[0], inplace=True)\n",
    "trade_values_df.index.name = \"timestamp\"\n",
    "trade_values_df = trade_values_df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required columns:\n",
    "required_columns = {\"Trade Close\", \"Trade High\", \"Trade Low\", \"Trade Open\", \"Trade Volume\"}\n",
    "\n",
    "# extract all tickers from the first level of the columns\n",
    "tickers = trade_values_df.columns.levels[0]\n",
    "\n",
    "valid_tickers = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    # the sub-columns (second-level) for this particular ticker\n",
    "    subcols = set(trade_values_df[ticker].columns)\n",
    "    \n",
    "    # check if all required columns are present\n",
    "    if required_columns.issubset(subcols):\n",
    "        \n",
    "        # now check how many valid rows the ticker has.\n",
    "        subdf = trade_values_df[ticker][list(required_columns)]\n",
    "        \n",
    "        # count rows that are non-null in *all* required columns:\n",
    "        non_null_rows = subdf.dropna(how=\"any\").shape[0]\n",
    "        \n",
    "        if non_null_rows >= 13: # we uses 12 month momentum hence need at least 13 months of data to get even one valid data point\n",
    "            valid_tickers.append(ticker)\n",
    "\n",
    "# filter the original df to keep only valid tickers and all their second-level columns:\n",
    "trade_df = trade_values_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Extract valid stocks and informtion on them](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_58064/1566292336.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stocks_df.rename(columns={'Code': 'Ticker'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# clean stock names\n",
    "stocks_df = eikon_dfs['Unique Stocks'].iloc[:,0:3]\n",
    "# rename Code to Ticker\n",
    "stocks_df.rename(columns={'Code': 'Ticker'}, inplace=True)\n",
    "\n",
    "# use valid_tickers to filter the stocks_df\n",
    "stocks_df = stocks_df[stocks_df['Ticker'].isin(valid_tickers)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nace_df = eikon_dfs['NACE'].iloc[1:,1:3]\n",
    "\n",
    "# rename columns\n",
    "nace_df.columns = ['Ticker', 'NACE']\n",
    "\n",
    "# identify the NACE codes\n",
    "nace_df['NACE'] = nace_df['NACE'].str.extract(r'\\((\\d+(?:\\.\\d+)?)\\)$')\n",
    "\n",
    "# manually map remaining NACE codes to companies\n",
    "manual_nace = {'CEMAT.CO':'68.20',\n",
    "               'CICC.CO^L01':'70.10',\n",
    "               'DAI.CO^A02':'70.10',\n",
    "               'GR4.CO^A05':'80.10',\n",
    "               'GR4n1.CO^J04':'80.10',\n",
    "               'GR4n2.CO^J04':'80.10',\n",
    "               'IFAC.CO^D03':'64.30',\n",
    "               'INVb.CO^F05':'64.30',\n",
    "               'IPFCa.CO^G02':'70.10',\n",
    "               'IPFCb.CO^G02':'70.10',\n",
    "               'OBJCa.CO^D02':'62.01',\n",
    "               'OBJCb.CO^D02':'62.01',\n",
    "               'ORSTED.CO':'35.11',\n",
    "               'POFLSb.CO^H06':'64.30',\n",
    "               'POKAP.CO^B06':'64.30',\n",
    "               'RADIb.CO^C04':'32.50',\n",
    "               'TRMC.CO^H02':'64.19',\n",
    "               'VEND.CO^C02':'64.19'}\n",
    "\n",
    "for ticker, nace_code in manual_nace.items():\n",
    "    if ticker in nace_df['Ticker'].values:\n",
    "        nace_df.loc[nace_df['Ticker'] == ticker, 'NACE'] = nace_code\n",
    "    else:   \n",
    "        print(f\"Ticker {ticker} not found in NACE DataFrame.\")\n",
    "\n",
    "# split the NACE codes into separate columns\n",
    "nace_df['NACE'] = nace_df['NACE'].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_df = eikon_dfs['Outstanding Shares'].iloc[:,1:]\n",
    "\n",
    "# make first row the header\n",
    "shares_df.columns = shares_df.iloc[0]\n",
    "shares_df = shares_df[1:]\n",
    "\n",
    "# rename the first column to 'Ticker'\n",
    "shares_df.rename(columns={shares_df.columns[0]: 'Ticker'}, inplace=True)\n",
    "\n",
    "# set columns to type numeric and findf the valid first occurrence\n",
    "shares_df.iloc[:, 1:] = shares_df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "shares_df['Shares'] = shares_df.apply(lambda row: first_valid(row, shares_df.columns[1:]),axis=1)\n",
    "\n",
    "# drop all columns except 'Ticker' and 'Shares'\n",
    "shares_df = shares_df[['Ticker', 'Shares']]\n",
    "\n",
    "# manually add shares for some tickers\n",
    "manual_shares = {\n",
    "    'ALBCb.CO^F02': 577000,\n",
    "    'DAI.CO^A02': 291250,\n",
    "    'FRINV.CO^A02': 803451,\n",
    "    'IFAC.CO^D03': 450000,\n",
    "    'IPFCa.CO^G02': 4463748,\n",
    "    'IPFCb.CO^G02': 4463748,\n",
    "    'SAMC.CO^G03': 205190,\n",
    "    'TRMC.CO^H02': 180000,\n",
    "    'VEND.CO^C02': 155000\n",
    "}\n",
    "\n",
    "for ticker, shares in manual_shares.items():\n",
    "    if ticker in shares_df['Ticker'].values:\n",
    "        shares_df.loc[shares_df['Ticker'] == ticker, 'Shares'] = shares\n",
    "    else:   \n",
    "        print(f\"Ticker {ticker} not found in Shares DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the stocks_df with the nace_df df\n",
    "stocks_df = stocks_df.merge(shares_df, how='left', on='Ticker')\n",
    "stocks_df = stocks_df.merge(nace_df, how='left', on='Ticker')\n",
    "\n",
    "# rename columns\n",
    "stocks_df.rename(columns={\n",
    "    'Ticker': 'ticker',\n",
    "    'Name': 'name',\n",
    "    'Shares': 'shares',\n",
    "    'Code incl. Expiration':'code_incl_expiration',\n",
    "    'NACE': 'NACE',\n",
    "}, inplace=True)\n",
    "\n",
    "# save as stocks\n",
    "stocks_df.to_csv('data/stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Clean P/E, Turnover, Bid, and Ask data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[P/E](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies with no PE ratio in the entire period: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "pe_ratio_df = eikon_dfs['PE Ratio'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "pe_ratio_df.columns = pd.MultiIndex.from_arrays(pe_ratio_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "pe_ratio_df = pe_ratio_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "pe_ratio_df.set_index(pe_ratio_df.columns[0], inplace=True)\n",
    "pe_ratio_df.index.name = \"timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "pe_ratio_df = pe_ratio_df.loc[:, (valid_tickers, slice(None))]\n",
    "\n",
    "# rename all the columns called 'PERATIO' to 'PE Ratio'\n",
    "pe_ratio_df.columns = [(ticker, 'PE Ratio') if col == 'PERATIO' else (ticker, col) for ticker, col in pe_ratio_df.columns]\n",
    "\n",
    "# Count columns (tickers) where all values are NaN\n",
    "count_no_pe = pe_ratio_df.isna().all(axis=0).sum()\n",
    "\n",
    "print(f\"Companies with no PE ratio in the entire period: {count_no_pe}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[Turnover](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "turnover_df = eikon_dfs['Turnover'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "turnover_df.columns = pd.MultiIndex.from_arrays(turnover_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "turnover_df = turnover_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "turnover_df.set_index(turnover_df.columns[0], inplace=True)\n",
    "turnover_df.index.name = \"timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "turnover_df = turnover_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_4_'></a>[Ask](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "ask_df = eikon_dfs['Ask'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "ask_df.columns = pd.MultiIndex.from_arrays(ask_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "ask_df = ask_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "ask_df.set_index(ask_df.columns[0], inplace=True)\n",
    "ask_df.index.name = \"timestamp\"\n",
    "# filter to only include valid tickers\n",
    "ask_df = ask_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_5_'></a>[Bid](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "bid_df = eikon_dfs['Bid'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "bid_df.columns = pd.MultiIndex.from_arrays(bid_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "bid_df = bid_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "bid_df.set_index(bid_df.columns[0], inplace=True)\n",
    "bid_df.index.name = \"timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "bid_df = bid_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_6_'></a>[divdend](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_df = eikon_dfs['Dividend'].iloc[:,1:]\n",
    "\n",
    "# set the first row as header\n",
    "div_df.columns = div_df.iloc[0]\n",
    "div_df = div_df[1:]\n",
    "\n",
    "# set first name of first column as ticker\n",
    "div_df.rename(columns={div_df.columns[0]: 'ticker'}, inplace=True)\n",
    "\n",
    "# if divdend pay date is not available use date, if adj net divdend is not available use adj gross divdend\n",
    "div_df['div'] = div_df.apply(lambda row: first_valid(row, ['Adjusted Net Dividend Amount', 'Adjusted Gross Dividend Amount']), axis=1)\n",
    "div_df['timestamp'] = div_df.apply(lambda row: first_valid(row, ['Dividend Pay Date', 'Date']), axis=1)\n",
    "\n",
    "# drop all columns except 'Ticker' and 'divdend'\n",
    "div_df = div_df[['ticker', 'timestamp', 'div']]\n",
    "\n",
    "# convert timestamp to datetime\n",
    "div_df['timestamp'] = pd.to_datetime(div_df['timestamp'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# convert div to numeric\n",
    "div_df['div'] = pd.to_numeric(div_df['div'], errors='coerce')\n",
    "\n",
    "# # create a column with yearly divdend\n",
    "# div_df['dyearly'] = div_df.groupby('ticker')['div'].transform(lambda x: x.fillna(0).rolling(12).sum())\n",
    "\n",
    "# convert timestamp to end of month\n",
    "div_df['timestamp'] = div_df['timestamp'] + pd.offsets.MonthEnd(0)\n",
    "\n",
    "#sum the divdends for each ticker and month\n",
    "div_df = div_df.groupby(['ticker', 'timestamp'], as_index=False).agg({'div': 'sum'})\n",
    "\n",
    "div_wide = div_df.pivot(index='timestamp', columns='ticker', values='div')\n",
    "\n",
    "# add a second level under each ticker called \"divdend\"\n",
    "div_wide.columns = pd.MultiIndex.from_product(\n",
    "    [div_wide.columns, ['div']],\n",
    "    names=['ticker', 'metric']\n",
    ")\n",
    "\n",
    "# add missing tickers from valid_tickers\n",
    "for ticker in valid_tickers:\n",
    "    if ticker not in div_wide.columns.get_level_values(0):\n",
    "        div_wide[ticker, 'div'] = np.nan\n",
    "\n",
    "# filter to isin valid tickers\n",
    "div_wide = div_wide.loc[:, (valid_tickers, slice(None))]\n",
    "\n",
    "# set nan to 0\n",
    "div_wide = div_wide.fillna(0)\n",
    "\n",
    "# sorted datetime index\n",
    "div_wide.index = pd.to_datetime(div_wide.index)\n",
    "div_wide = div_wide.sort_index()\n",
    "\n",
    "# slice out just the divdend columns: a DF of shape (time × tickers)\n",
    "divs = div_wide.xs('div', level='metric', axis=1)\n",
    "\n",
    "# compute a 365‑day rolling sum on each column independently\n",
    "yearly = divs.rolling(window='365D').sum()\n",
    "\n",
    "# re‑label its columns to match MultiIndex \n",
    "yearly.columns = pd.MultiIndex.from_product(\n",
    "    [yearly.columns, ['div_annual']],\n",
    "    names=div_wide.columns.names\n",
    ")\n",
    "div_wide = pd.concat([div_wide, yearly], axis=1)\n",
    "\n",
    "\n",
    "# compute “initiated” and “halted” on the yearly divdend\n",
    "year = div_wide.xs('div_annual', level='metric', axis=1)\n",
    "prev_year = year.shift(1)\n",
    "\n",
    "# initiated: was ≤0 or NaN, now >0\n",
    "initiated = ((prev_year.fillna(0) == 0) & (year > 0)).astype(int)\n",
    "\n",
    "# halted: was >0, now ≤0 or NaN\n",
    "halted = ((prev_year > 0) & (year.fillna(0) == 0)).astype(int)\n",
    "\n",
    "# label those flags as their own metrics\n",
    "initiated.columns = pd.MultiIndex.from_product(\n",
    "    [initiated.columns, ['divi']],\n",
    "    names=div_wide.columns.names\n",
    ")\n",
    "halted.columns = pd.MultiIndex.from_product(\n",
    "    [halted.columns, ['divo']],\n",
    "    names=div_wide.columns.names\n",
    ")\n",
    "\n",
    "# 8) final concat and sort\n",
    "div_wide = pd.concat([div_wide, initiated, halted], axis=1)\n",
    "div_wide = div_wide.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_7_'></a>[Join all dataframes](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trade_df.join([\n",
    "    # pe_ratio_df, \n",
    "    turnover_df, \n",
    "    ask_df, \n",
    "    bid_df,\n",
    "    ],how='outer')\n",
    "\n",
    "df = df.join(div_wide, how='left')\n",
    "\n",
    "# sort columns by the first level of the multi-index\n",
    "df = df.sort_index(axis=1, level=0)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an IndexSlice for easier multi-index slicing\n",
    "idx = pd.IndexSlice\n",
    "# loop over the tickers that are actually in the df\n",
    "for ticker in df.columns.get_level_values(0).unique():\n",
    "    # extract the sub-dataframe for this ticker using .loc with IndexSlice\n",
    "    subdf = df.loc[:, idx[ticker, :]]\n",
    "    # find the index range where the ticker has any valid data\n",
    "    valid_idx = subdf.dropna(how='all').index\n",
    "    # use backward fill in the date range\n",
    "    df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]] = df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]].bfill()\n",
    "\n",
    "df = df.rename(columns={'Ask Close':'ask',\n",
    "                        'Bid Close':'bid',\n",
    "                        'PE Ratio':'pe_ratio',\n",
    "                        'Trade Close':'adjclose',\n",
    "                        'Trade High':'high',\n",
    "                        'Trade Low':'low',\n",
    "                        'Trade Open':'open',\n",
    "                        'Trade Volume':'volume',\n",
    "                        'Turnover':'turnover'})\n",
    "\n",
    "# save df\n",
    "df.to_csv('data/trade.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
