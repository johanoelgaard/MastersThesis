{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2234b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e75ef2",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Combining data sources](#toc1_)    \n",
    "    - [Add industry data for DK](#toc1_1_1_)    \n",
    "    - [Add financial data](#toc1_1_2_)    \n",
    "    - [Add beta](#toc1_1_3_)    \n",
    "  - [Add risk-free rate](#toc1_2_)    \n",
    "- [Create variables](#toc2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a83dd",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Combining data sources](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e837b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = pd.read_csv('data/trade.csv', header=[0,1], index_col=0)\n",
    "stocks = pd.read_csv('data/stocks.csv')\n",
    "dk_industry = pd.read_csv('data/dk_industry.csv')\n",
    "financials = pd.read_csv('data/financials.csv')\n",
    "# beta = pd.read_csv('data/beta.csv')\n",
    "rf_rate = pd.read_csv('data/rf_rate.csv')\n",
    "trade_daily = pd.read_csv('data/trade_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e88d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offsets\n",
    "quarterly_offset = 3 # quarterly data is 2 months behind end of quarter\n",
    "annual_offset = 6 # annual data is 6 months behind publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c20f8a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_39625/654452550.py:3: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  trade = trade.stack(level=0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# convert the index to datetime (the index holds the dates)\n",
    "trade.index = pd.to_datetime(trade.index)\n",
    "trade = trade.stack(level=0).reset_index()\n",
    "\n",
    "\n",
    "# rename columns to have a proper\n",
    "trade.rename(columns={'level_1': 'ticker'}, inplace=True)\n",
    "\n",
    "# Data Cleaning and Sorting\n",
    "trade.drop_duplicates(inplace=True)\n",
    "trade.dropna(inplace=True) # happens if there was one data point the first day of a given ticker but not the rest of the values (e.g. trade values but no ask or bid)\n",
    "trade.sort_values(['ticker', 'timestamp'], inplace=True)\n",
    "trade.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d08b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(trade, stocks[['ticker','shares','NACE']], how='left', on=['ticker'])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41841a07",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc1_1_1_'></a>[Add industry data for DK](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99b8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_industry['timestamp'] = pd.to_datetime(dk_industry['timestamp'])\n",
    "# join stocks and dk_industry on 'NACE industry' \n",
    "industry = stocks[['ticker','NACE']].merge(dk_industry, how='left', on='NACE')\n",
    "\n",
    "# adjust the timestamp to be 2 months behind\n",
    "industry['timestamp'] = industry['timestamp'] + pd.DateOffset(months=quarterly_offset)\n",
    "industry['timestamp'] = (\n",
    "    industry['timestamp']\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')\n",
    ")\n",
    "\n",
    "industry = industry.drop(columns=['NACE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a40918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, industry, how='left', on=['timestamp', 'ticker'])\n",
    "\n",
    "#ffil the industry values\n",
    "for col in industry.columns[2:]:\n",
    "    df[col] = df[col].groupby(df['ticker']).ffill()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fadcf1",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Add financial data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da67cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "financials['timestamp'] = pd.to_datetime(financials['timestamp'])\n",
    "\n",
    "financials['timestamp'] = financials['timestamp'] + pd.DateOffset(months=annual_offset)\n",
    "financials['timestamp'] = (\n",
    "    financials['timestamp']\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')\n",
    ")\n",
    "\n",
    "# expand the dataset\n",
    "financials = (\n",
    "    financials\n",
    "        # sort data and find the next timestamp\n",
    "      .sort_values(['ticker','timestamp'])\n",
    "      .assign(\n",
    "        next_fye   = lambda df: df.groupby('ticker')['timestamp'].shift(-1),\n",
    "        plus_12m   = lambda df: df['timestamp'] + pd.DateOffset(months=12),\n",
    "        period_end = lambda df: pd.to_datetime(np.where(\n",
    "                          (df.next_fye - df.timestamp).abs()\n",
    "                            < \n",
    "                          (df.plus_12m   - df.timestamp).abs(),\n",
    "                          df.next_fye,\n",
    "                          df.plus_12m\n",
    "                        ))\n",
    "      )\n",
    "      # expand the data\n",
    "      .assign(timestamp = lambda df: df.apply(expand_monthly, axis=1))\n",
    "      .explode('timestamp')\n",
    "      .drop(columns=['next_fye','plus_12m','period_end'])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# display(financials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d792d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df and financials\n",
    "df = pd.merge(df, financials, how='left', on=['timestamp', 'ticker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d78013",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Add variables calculated on daily data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7038c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_daily['timestamp'] = pd.to_datetime(trade_daily['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add6ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcfe8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df and beta\n",
    "df = pd.merge(df, trade_daily, how='left', on=['timestamp', 'ticker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8cbf9",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Add risk-free rate](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478da9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rate['timestamp'] = pd.to_datetime(rf_rate['timestamp'])\n",
    "# set date as index and resample by month, taking the mean of diskonto & folio\n",
    "monthly_avg = (\n",
    "    rf_rate\n",
    "    .set_index('timestamp')\n",
    "    .resample('ME')[['diskonto', 'folio']]\n",
    "    .mean()\n",
    "    .rename_axis('timestamp')\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to monthly rates\n",
    "monthly_avg['diskonto'] = monthly_avg['diskonto'].apply(lambda x: (1 + x) ** (1/12) - 1)\n",
    "monthly_avg['folio'] = monthly_avg['folio'].apply(lambda x: (1 + x) ** (1/12) - 1)\n",
    "monthly_avg\n",
    "# drop diskonto and rename folio to risk-free\n",
    "monthly_avg.drop(columns=['diskonto'], inplace=True)\n",
    "monthly_avg.rename(columns={'folio': 'risk_free'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b2693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df and beta\n",
    "df = pd.merge(df, monthly_avg, how='left', on=['timestamp'])\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312089a",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Feature engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e237e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df['adjclose_div'] = df['adjclose'] + df['div'] # adjcose incl monthly dividend\n",
    "df['target'] = df.groupby('ticker')['adjclose_div'].transform(lambda x: x.pct_change(periods=1, fill_method=None))\n",
    "\n",
    "# subtract the risk-free rate from the target\n",
    "# df['target'] = df['target'] - df['risk_free']\n",
    "df['target'] = df['target'].shift(-1) # shift the target by 1 month\n",
    "\n",
    "df['mcap'] = df['adjclose'] * df['shares'] # market cap\n",
    "\n",
    "# other features\n",
    "df['acc'] = (df['netinc'] - df['cashflow'])/df['assets'] # accruals\n",
    "\n",
    "df['absacc'] = np.abs(df['acc']) # absolute accruals\n",
    "\n",
    "df['aeavol'] = None # abnormal earnings announcement volume\n",
    "\n",
    "df['age'] = (df['timestamp'] - df.groupby('ticker')['timestamp'].transform('min')).dt.days / 365.25 # age of the stock\n",
    "\n",
    "df['agr'] = (df.groupby('ticker')['assets'].transform(lambda x: x.pct_change(periods=12, fill_method=None))).fillna(0) # yearly asset growth\n",
    "\n",
    "df['betasq'] = df['betasq'] # beta squared\n",
    "\n",
    "df['bm'] = (df['assets'] - df['debt']) / df['mcap'] # book to market ratio #nb to check if debt includes both current and long term liabilities (pretty sure it does)\n",
    "\n",
    "df['bm_ia'] = None # industry adjusted book to market ratio\n",
    "\n",
    "df['cash'] = (df['cash'] / df['assets']).replace([np.inf, -np.inf], 0) # cash to assets ratio\n",
    "\n",
    "df['cashdebt'] = (df['cashflow'] / df['debt']).fillna(0).replace([np.inf, -np.inf], 0) # cashflow to debt ratio\n",
    "\n",
    "df['cashpr'] = ((df['mcap'] + df['debt'] - df['assets']) / df['cash']).fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "df['cfp'] = df['cashflow'] / df['mcap'] # cashflow to market cap ratio\n",
    "\n",
    "df['cfp_ia'] = df['cfp'] - df.groupby(['NACE','timestamp'])['cfp'].transform('mean') # industry adjusted cashflow to market cap ratio\n",
    "\n",
    "df['chat'] = (df['revenue']/ df['assets']).transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0).replace([np.inf, -np.inf], 0) # change in total assets\n",
    "df['chatoia'] = df['chat'] - df.groupby(['NACE','timestamp'])['chat'].transform('mean') # industry adjusted change in total assets\n",
    "df.drop(columns=['chat'], inplace=True) # only used for this calculation\n",
    "\n",
    "df['chcsho'] = None # change in common shares outstanding\n",
    "\n",
    "df['chempia'] = None # industry adjusted change in employees\n",
    "\n",
    "df['chinv'] = df.groupby('ticker')['currentassets'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "df['chmom'] = df['mom6m'] - df['mom7_12m'] # change in momentum\n",
    "df.drop(columns=['mom7_12m'], inplace=True) # only used for this calculation\n",
    "\n",
    "df['chpm'] = (df['opinc'] / df['revenue']).fillna(0).replace([np.inf, -np.inf], 0) # change in profit margin\n",
    "df['chpmia'] = df['chpm'] - df.groupby(['NACE','timestamp'])['chpm'].transform('mean') # industry adjusted change in profit margin\n",
    "df.drop(columns=['chpm'], inplace=True) # only used for this calculation\n",
    "\n",
    "df['chtx'] = None # change in tax rate\n",
    "\n",
    "df['cinvest'] = None # corporate investment\n",
    "\n",
    "df['convdebt'] = None # convertible debt\n",
    "\n",
    "df['depr'] = None # depreciation/PP&E\n",
    "\n",
    "df['divi'] = df['divi'].fillna(0) # dividens initiation\n",
    "\n",
    "df['divo'] = df['divo'].fillna(0) # dividens omission\n",
    "\n",
    "df['dkkvol'] = df['dkkvol'] # dkk volume (dollar volume in Gu et. al.)\n",
    "\n",
    "df['dy'] = df['dy']/df['adjclose'] # dividend to price (annualized)\n",
    "\n",
    "df['ear'] = None # earnings announcement return\n",
    "\n",
    "df['egr'] = df.groupby('ticker')['equity'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0) # growth in common shareholders equity\n",
    "\n",
    "df['ep'] = df['revenue'] / df['mcap'] # earnings to market cap ratio\n",
    "\n",
    "df['gma'] = df['grossprofit'] / df['assets'] # gross profitability\n",
    "\n",
    "df['grCAPX'] = None # growth in capital expenditures\n",
    "\n",
    "df['grltnoa'] = (df['assets'] - df['currentassets']).transform(lambda x: x.pct_change(periods=12, fill_method=None).replace([np.inf, -np.inf], 0)).fillna(0) # growth in long-term net operating assets\n",
    "\n",
    "df['herf'] = None # herfindahl index\n",
    "\n",
    "df['hire'] = None # hiring\n",
    "\n",
    "df['idiovol'] = df['idiovol'] # idiosyncratic volatility\n",
    "\n",
    "df['ill'] = df['ill'] # illiquidity (to be calculated on the daily data)\n",
    "\n",
    "df['indmom'] = df.groupby(['NACE', 'timestamp'])['mom12m'].transform('mean') # industry momentum\n",
    "\n",
    "df['invest'] = None # capital expenditures and investment\n",
    "\n",
    "df['lev'] = df['debt'] / df['assets'] # leverage\n",
    "\n",
    "df['lgr'] = df.groupby('ticker')['longdebt'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0).replace([np.inf, -np.inf], 0) # long-term debt growth\n",
    "\n",
    "df['maxret'] = df['maxret'] # maximum daily return\n",
    "\n",
    "df['ms'] = None # financial statement score\n",
    "\n",
    "df['mvel1'] = np.log(df['mcap']) # Size (log of market cap)\n",
    "\n",
    "df['mve_ia'] = df['mvel1'] - df.groupby(['NACE','timestamp'])['mvel1'].transform('mean') # industry adjusted size\n",
    "\n",
    "df['nincr'] = None # number of earnings increases\n",
    "\n",
    "df['operprof'] = df['opinc'] / df['assets'] # operating profitability\n",
    "\n",
    "df['orgcap'] = None # organizational capital\n",
    "\n",
    "df['pchcapx_ia'] = None # industry adjusted % change in capital expenditures\n",
    "\n",
    "df['pchcurrat'] = (df.groupby('ticker')['currentassets'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).replace([np.inf, -np.inf], 0)).fillna(0) # % change in current ratio\n",
    "\n",
    "# df['pchdpr'] = df.groupby('ticker')['depreciation'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0) # % change in depreciation\n",
    "\n",
    "df['pchgm_pchsale'] = (df.groupby('ticker')['grossprofit'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).replace([np.inf, -np.inf], 0) \n",
    "                       - df.groupby('ticker')['revenue'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).replace([np.inf, -np.inf], 0)).fillna(0) # % change in gross margin - % change in sales\n",
    "\n",
    "df['pchquick'] = (df.groupby('ticker')['quick'].transform(lambda x: x.pct_change(periods=12, fill_method=None))).fillna(0).replace([np.inf, -np.inf], 0) # % change in quick ratio\n",
    "\n",
    "df['pchsale_pchinvt'] = (df.groupby('ticker')['revenue'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).replace([np.inf, -np.inf], 0) \n",
    "                         - df.groupby('ticker')['currentassets'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).replace([np.inf, -np.inf], 0)).fillna(0) # % change in sales - % change in inventory\n",
    "\n",
    "# df['pchsale_pchrect'] = df.groupby('ticker')['revenue'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0) - df.groupby('ticker')['receivables'].transform(lambda x: x.pct_change(periods=12, fill_method=None)).fillna(0) # % change in sales - % change in receivables\n",
    "\n",
    "df['pchsale_pchxsga'] = None # % change in sales - % change in SG&A\n",
    "\n",
    "df['saleinv'] = (df['revenue'] / df['currentassets']).fillna(0).replace([np.inf, -np.inf], 0) # sales to inventory ratio\n",
    "\n",
    "df['pchsaleinv'] = (df.groupby('ticker')['saleinv'].transform(lambda x: x.pct_change(periods=12, fill_method=None))).fillna(0).replace([np.inf, -np.inf], 0) # % change in sales to inventory ratio\n",
    "\n",
    "df['pctacc'] = (df['netinc'] - df['cashflow'])/np.abs(df['netinc'].replace(0,0.01)) # % accruals\n",
    "\n",
    "df['pricedelay'] = df['pricedelay']  # price delay\n",
    "\n",
    "df['ps'] = None # financial statements score\n",
    "\n",
    "df['quick'] = df['quick'] # quick ratio\n",
    "\n",
    "df['rd'] = (df.groupby('ticker')['rnd'].transform(lambda x: x.pct_change(periods=12, fill_method=None))).fillna(0).replace([np.inf, -np.inf], 0) # R&D increase\n",
    "\n",
    "df['rd_mve'] = df['rnd'].fillna(0) / df['mcap'] # R&D to market cap ratio\n",
    "\n",
    "df['rd_sale'] = (df['rnd'].fillna(0) / df['revenue']).fillna(0).replace([np.inf, -np.inf], 0) # R&D to sales ratio\n",
    "\n",
    "df['realestate'] = None # real estate holdings\n",
    "\n",
    "df['retvol'] = df['retvol'] # return volatility\n",
    "\n",
    "df['roaq'] = df['netinc'] / df['assets'] # return on assets\n",
    "\n",
    "df['roavol'] = None # earning volatility\n",
    "\n",
    "df['roeq'] = df['netinc'] / df['equity'] # return on equity\n",
    "\n",
    "df['roic'] = df['netinc'] / (df['liabilities_equity']) # return on invested capital\n",
    "\n",
    "df['rsup'] = None # revenue surprise\n",
    "\n",
    "df['salecash'] = (df['revenue'] / df['cash']).fillna(0).replace([np.inf, -np.inf], 0).replace([np.inf, -np.inf], 0) # sales to cash ratio \n",
    "\n",
    "# df['salerec'] =  df['revenue'] / df['receivables'] # sales to receivables ratio\n",
    "\n",
    "df['secured'] = None # secured debt\n",
    "\n",
    "df['securedind'] = None # secured debt indicator\n",
    "\n",
    "df['sgr'] = (df.groupby('ticker')['revenue'].transform(lambda x: x.pct_change(periods=12, fill_method=None))).fillna(0).replace([np.inf, -np.inf], 0) # sales growth\n",
    "\n",
    "df['sin'] = None # sin stock indicator\n",
    "\n",
    "df['sp'] = df['revenue'].fillna(0) / df['mcap'] # sales to price ratio\n",
    "\n",
    "df['std_dkkvol'] = df['std_dkkvol']  # standard deviation of dkk volume\n",
    "\n",
    "df['std_turn'] = df['std_turn']  # standard deviation of turnover\n",
    "\n",
    "df['stdacc'] = None # standard deviation of accruals\n",
    "\n",
    "df['stdcf'] = None # standard deviation of cashflow\n",
    "\n",
    "df['tang'] = None # debt capacity/firm tangibility\n",
    "\n",
    "df['tb'] = None # tax income to book income\n",
    "\n",
    "df['turn'] = df['turn']  # turnover\n",
    "\n",
    "df['zerotrade'] = df['zerotrade'] # zero trading days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e44c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fin_df = df.copy()\n",
    "\n",
    "# fin_df['adjclose_div'] = fin_df['adjclose'] + fin_df['div'] # adjcose incl monthly dividend\n",
    "# fin_df['target'] = fin_df.groupby('ticker')['adjclose_div'].transform(lambda x: x.pct_change(periods=1, fill_method=None))\n",
    "# fin_df['target'] = fin_df['target'].shift(-1) # shift the target by 1 month\n",
    "\n",
    "# # drop rows where mom12m is NaN\n",
    "# fin_df.dropna(subset=['mom12m','target'], inplace=True)\n",
    "\n",
    "# for col in fin_df.columns:\n",
    "#     if fin_df[col].isnull().all():\n",
    "#         fin_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "\n",
    "# fin_df['year'] = fin_df['timestamp'].dt.year\n",
    "\n",
    "# # 3. Group, count NaNs, then filter out all-zero rows\n",
    "# nan_summary = (\n",
    "#     fin_df\n",
    "#     .groupby(['ticker','year'])\n",
    "#     .apply(lambda grp: grp.isna().sum())                # count NaNs column-wise\n",
    "#     .drop(columns=['timestamp','ticker','year'])         # drop grouping cols\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# # 4. Keep only rows where there’s at least one missing value\n",
    "# #    (i.e. the row-sum of NaNs across data columns > 0)\n",
    "# data_cols    = nan_summary.columns.difference(['ticker','year'])\n",
    "# nan_summary  = nan_summary[nan_summary[data_cols].sum(axis=1) > 0]\n",
    "# # nan_summary.drop(columns=['ask','bid','adjclose','high','low','open','turnover','div','beta','betasq','idiovol','pricedelay','mom1m','mom6m','mom12m','mom7_12m','adjclose_div','target','divi','divo','dy', 'shares','NACE','grossoutput','intercons'], inplace=True)\n",
    "\n",
    "# display(nan_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f493de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assume you already have:\n",
    "# #   nan_summary with columns ['ticker','year', <all your data-columns>]\n",
    "\n",
    "# # 1. Identify just the “data” columns (i.e. drop the grouping cols)\n",
    "# data_cols = nan_summary.columns.difference(['ticker','year'])\n",
    "\n",
    "# # 2. Compute total missing per ticker\n",
    "# #    - group by ticker, sum each data column over all years\n",
    "# #    - then sum across those columns to get one number per ticker\n",
    "# ticker_missing = (\n",
    "#     nan_summary\n",
    "#     .groupby('ticker')[data_cols]    # group & select data cols\n",
    "#     .sum()                           # sum each col over years\n",
    "#     .sum(axis=1)                     # sum across cols → one total per ticker\n",
    "# )\n",
    "\n",
    "# # 3. Compute total missing per column\n",
    "# #    - just sum each column over all rows (ticker-years)\n",
    "# column_missing = nan_summary[data_cols].sum()\n",
    "\n",
    "# # 4. Print them out\n",
    "# print(\"Missing values by ticker:\")\n",
    "# print(ticker_missing)\n",
    "\n",
    "# # Filter to only cols with >0 missing\n",
    "# nonzero_column_missing = column_missing[column_missing > 0]\n",
    "\n",
    "# print(\"Missing values by column (only non-zero):\")\n",
    "# print(nonzero_column_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3d39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not needed\n",
    "df.drop(columns=['adjclose', 'high', 'low', 'open', 'div', 'ask', 'bid','turnover','shares',\n",
    "                 'grossoutput', 'intercons', 'prodind', 'valaddoutput',\n",
    "                 'risk_free',\n",
    "                 'assets', 'debt', 'opinc', 'netinc', 'rnd', 'cashflow', 'revenue', 'grossprofit', 'currentassets', 'volume',\n",
    "                 'currentliabilities', 'liabilities_equity', 'assets', 'longdebt', 'receivables', 'depreciation', 'equity' \n",
    "                 ], inplace=True)\n",
    "\n",
    "# remove empty columns (None from above)\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().all():\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# drop if mom12m or target is nan (first 12 months and last month for each ticker)\n",
    "df.dropna(subset=['mom12m','target'], inplace=True)\n",
    "\n",
    "# drop if any nan\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# cols = df.columns\n",
    "# cols = cols.sort_values()\n",
    "# for col in cols:\n",
    "#     if col in ['NACE']:\n",
    "#         continue\n",
    "#     print(f'{col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49915bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a6b9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables for the industry\n",
    "industry_dummies = pd.get_dummies(df['NACE'], prefix='NACE')\n",
    "df = pd.concat([df, industry_dummies], axis=1)\n",
    "df.drop(columns=['NACE'], inplace=True)\n",
    "\n",
    "# create dummies for the month\n",
    "month_dummies = pd.get_dummies(df['timestamp'].dt.month, prefix='month')\n",
    "df = pd.concat([df, month_dummies], axis=1)\n",
    "\n",
    "# save the data\n",
    "df.to_csv('data/data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
