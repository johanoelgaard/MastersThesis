{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import re\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "parent_dir = Path().resolve().parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from libs.functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76e3a1",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba903c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "path = '/Users/johan/Library/CloudStorage/GoogleDrive-johan.oelgaard@gmail.com/My Drive/04 Økonomi/10 Thesis/Data'\n",
    "\n",
    "# read daily market data from eikon\n",
    "daily = 'eikon_daily.xlsx'\n",
    "eikon_dfs = pd.read_excel(path + '/' + daily, sheet_name=None)\n",
    "eikon_keys = eikon_dfs.keys()\n",
    "\n",
    "monthly_ = 'eikon_monthly.xlsx'\n",
    "eikon_divi = pd.read_excel(path + '/' + monthly_, sheet_name='Dividend', header=1)\n",
    "eikon_shares = pd.read_excel(path + '/' + monthly_, sheet_name='Outstanding Shares', header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc99d5",
   "metadata": {},
   "source": [
    "# Load in trading data and dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97852e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set first row as header\n",
    "divi = eikon_divi.iloc[:,1:].copy()\n",
    "divi.rename(columns={'Unnamed: 1': 'ticker', 'Date': 'announcement timestamp', 'Dividend Pay Date': 'timestamp', 'Adjusted Gross Dividend Amount': 'adjdivi gross', 'Adjusted Net Dividend Amount': 'adjdivi net'}, inplace=True)\n",
    "\n",
    "# if net dividend is not available, use gross dividend\n",
    "divi['adjdivi net'] = divi['adjdivi net'].fillna(divi['adjdivi gross'])\n",
    "divi['timestamp'] = divi['timestamp'].fillna(divi['announcement timestamp'])\n",
    "\n",
    "divi['timestamp'] = pd.to_datetime(divi['timestamp'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "# drop other columns\n",
    "divi = divi[['ticker', 'timestamp', 'adjdivi net']]\n",
    "divi = divi.rename(columns={'adjdivi net': 'dividend'})\n",
    "\n",
    "# drop na\n",
    "divi = divi.dropna().reset_index(drop=True)\n",
    "divi.set_index('timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a40ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# load trade data\n",
    "trade_values_df = eikon_dfs['Trade Values'].iloc[:,1:]\n",
    "# set up multi-index for the columns\n",
    "trade_values_df.columns = pd.MultiIndex.from_arrays(trade_values_df.iloc[:2].values)\n",
    "# drop the first two rows as they are now headers\n",
    "trade_values_df = trade_values_df.iloc[2:].reset_index(drop=True)\n",
    "# set the first column as index\n",
    "trade_values_df.set_index(trade_values_df.columns[0], inplace=True)\n",
    "trade_values_df.index.name = \"timestamp\"\n",
    "trade_values_df = trade_values_df.sort_index(axis=1, level=0)\n",
    "# keep only trade close values\n",
    "trade_values_df = trade_values_df.loc[:, (slice(None), ['Trade Close','Trade Volume'])]\n",
    "# set 0 values to NaN\n",
    "trade_values_df = trade_values_df.replace(0, np.nan)\n",
    "# display(trade_values_df.head())\n",
    "\n",
    "# backward fill the data for each ticker\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# loop over the tickers that are actually in the df\n",
    "for ticker in trade_values_df.columns.get_level_values(0).unique():\n",
    "    # extract the sub-dataframe for this ticker using .loc with IndexSlice\n",
    "    subdf = trade_values_df.loc[:, idx[ticker, :]]\n",
    "    \n",
    "    # find the index range where the ticker has any valid data\n",
    "    valid_idx = subdf.dropna(how='all').index\n",
    "\n",
    "    # use backward fill in the date range\n",
    "    trade_values_df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]] = trade_values_df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]].bfill()\n",
    "\n",
    "# stack first level of columns to rows\n",
    "trade_values_df = trade_values_df.stack(level=0,future_stack=True).reset_index()\n",
    "trade_values_df = trade_values_df.dropna()\n",
    "# display(trade_values_df.head())\n",
    "# rename columns\n",
    "trade_values_df.columns = ['timestamp', 'ticker', 'adjclose', 'volume']\n",
    "# set first column as index\n",
    "trade_values_df.set_index('timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181297ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dividend data\n",
    "df = trade_values_df.merge(divi, how='left', on=['ticker', 'timestamp'])\n",
    "# manually\n",
    "# set dividend to 0 na\n",
    "df['dividend'] = df['dividend'].fillna(0)\n",
    "\n",
    "df['adjclose_divi'] = df['adjclose'] + df['dividend']\n",
    "\n",
    "# calculate the daily returns\n",
    "df = df.sort_values(by=['ticker', 'timestamp'], ascending=[True, True]).reset_index()\n",
    "df['stkre'] = df.groupby('ticker', group_keys=False)['adjclose_divi'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outstanding shares\n",
    "shares = eikon_shares.iloc[:,1:]\n",
    "shares.rename(columns={shares.columns[0]: 'ticker'}, inplace=True)\n",
    "# set columns to type numeric and findf the valid first occurrence\n",
    "shares.iloc[:, 1:] = shares.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "shares['shares'] = shares.apply(lambda row: first_valid(row, shares.columns[1:]),axis=1)\n",
    "# drop all columns except 'Ticker' and 'Shares'\n",
    "shares = shares[['ticker', 'shares']]\n",
    "manual_shares = {\n",
    "    'ALBCb.CO^F02': 577000,\n",
    "    'DAI.CO^A02': 291250,\n",
    "    'FRINV.CO^A02': 803451,\n",
    "    'IFAC.CO^D03': 450000,\n",
    "    'IPFCa.CO^G02': 4463748,\n",
    "    'IPFCb.CO^G02': 4463748,\n",
    "    'SAMC.CO^G03': 205190,\n",
    "    'TRMC.CO^H02': 180000,\n",
    "    'VEND.CO^C02': 155000\n",
    "}\n",
    "\n",
    "for ticker, shares_ in manual_shares.items():\n",
    "    if ticker in shares['ticker'].values:\n",
    "        shares.loc[shares['ticker'] == ticker, 'shares'] = shares_\n",
    "    else:   \n",
    "        print(f\"ticker {ticker} not found in Shares DataFrame.\")\n",
    "\n",
    "df = df.merge(shares, how='left', on='ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176a56f",
   "metadata": {},
   "source": [
    "# Load index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355cf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# load index data\n",
    "omxcpi = eikon_dfs['OMXCPI'].iloc[:,1:]\n",
    "# set first row as header\n",
    "omxcpi.columns = omxcpi.iloc[0]\n",
    "# drop the first row as it is now header\n",
    "omxcpi = omxcpi.iloc[1:].reset_index(drop=True)\n",
    "# set the first column as index\n",
    "omxcpi.set_index(omxcpi.columns[0], inplace=True)\n",
    "omxcpi.index.name = \"timestamp\"\n",
    "omxcpi = omxcpi.sort_index(axis=1)\n",
    "# keep only closing values\n",
    "omxcpi = omxcpi.loc[:,'Trade Close']\n",
    "# convert to dataframe\n",
    "omxcpi = pd.DataFrame(omxcpi)\n",
    "# rename columns\n",
    "omxcpi.columns = ['OMXCPI']\n",
    "\n",
    "omxcpi = omxcpi.sort_index(ascending=True)\n",
    "omxcpi['mktre'] = omxcpi['OMXCPI'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018037c",
   "metadata": {},
   "source": [
    "# Load additional trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a67cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "turnover_df = eikon_dfs['Turnover'].iloc[:,1:]\n",
    "ask_df = eikon_dfs['Ask'].iloc[:,1:]\n",
    "bid_df = eikon_dfs['Bid'].iloc[:,1:]\n",
    "\n",
    "\n",
    "turnover_df.columns = pd.MultiIndex.from_arrays(turnover_df.iloc[:2].values)\n",
    "turnover_df = turnover_df.iloc[2:].reset_index(drop=True)\n",
    "turnover_df.set_index(turnover_df.columns[0], inplace=True)\n",
    "turnover_df.index.name = \"timestamp\"  \n",
    "\n",
    "ask_df.columns = pd.MultiIndex.from_arrays(ask_df.iloc[:2].values)\n",
    "ask_df = ask_df.iloc[2:].reset_index(drop=True)\n",
    "ask_df.set_index(ask_df.columns[0], inplace=True)\n",
    "ask_df.index.name = \"timestamp\"\n",
    "\n",
    "bid_df.columns = pd.MultiIndex.from_arrays(bid_df.iloc[:2].values)\n",
    "bid_df = bid_df.iloc[2:].reset_index(drop=True)\n",
    "bid_df.set_index(bid_df.columns[0], inplace=True)\n",
    "bid_df.index.name = \"timestamp\"\n",
    "\n",
    "\n",
    "turnover_df = turnover_df.stack(level=0, future_stack=True).reset_index().set_index('timestamp')\n",
    "turnover_df.drop(columns=['TRNOVR_UNS'], inplace=True)\n",
    "# turnover_df.dropna(inplace=True)\n",
    "turnover_df.columns = ['ticker', 'turnover']\n",
    "\n",
    "ask_df = ask_df.stack(level=0, future_stack=True).reset_index().set_index('timestamp')\n",
    "ask_df.drop(columns=['ASK'], inplace=True)\n",
    "# ask_df.dropna(inplace=True)\n",
    "ask_df.columns = [ 'ticker', 'ask']\n",
    "\n",
    "bid_df = bid_df.stack(level=0,future_stack=True).reset_index().set_index('timestamp')\n",
    "bid_df.drop(columns=['BID'], inplace=True)\n",
    "# bid_df.dropna(inplace=True)\n",
    "bid_df.columns = ['ticker', 'bid']\n",
    "\n",
    "# merge w. trade values on index and ticker\n",
    "df = df.merge(turnover_df, on=['timestamp', 'ticker'], how='left')\n",
    "df = df.merge(ask_df, on=['timestamp', 'ticker'], how='left')\n",
    "df = df.merge(bid_df, on=['timestamp', 'ticker'], how='left')\n",
    "\n",
    "# prerequisites -------------------------------------------------------------\n",
    "df = df.sort_values(['ticker', 'timestamp'])         # already have the right order\n",
    "cols_to_ffill = ['turnover', 'ask', 'bid']           # numeric columns to fill\n",
    "\n",
    "# Identify where row have *any* real data?\n",
    "has_val = df[cols_to_ffill].notna().any(axis=1)      # boolean Series, same length as df\n",
    "\n",
    "#     Inside every ticker, mark rows that lie *after* the first real data point, AND *before* the last real data point.\n",
    "g = df['ticker']                                     # short alias\n",
    "\n",
    "# cummax() of True/False gives a running “ever seen True so far?”\n",
    "left_ok  = has_val.groupby(g).cummax()               # after (or at) 1st real value\n",
    "right_ok = has_val.iloc[::-1].groupby(g.iloc[::-1]) \\\n",
    "                        .cummax().iloc[::-1]         # before (or at) last real value\n",
    "\n",
    "mask = left_ok & right_ok                            # True only inside the window\n",
    "\n",
    "# compute a forward fill *inside each ticker* once\n",
    "filled = df.groupby(g, group_keys=False)[cols_to_ffill].ffill()\n",
    "\n",
    "# put the filled numbers back, but **only** where `mask` is True\n",
    "df.loc[mask, cols_to_ffill] = filled.loc[mask]\n",
    "\n",
    "# optionally get rid of rows that are still all-NaN\n",
    "df.dropna(subset=cols_to_ffill, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018b757",
   "metadata": {},
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables to numeric\n",
    "df['adjclose'] = pd.to_numeric(df['adjclose'], errors='coerce')\n",
    "df['volume'] = pd.to_numeric(df['volume'], errors='coerce')\n",
    "df['stkre'] = pd.to_numeric(df['stkre'], errors='coerce')\n",
    "df['turnover'] = pd.to_numeric(df['turnover'], errors='coerce')\n",
    "df['ask'] = pd.to_numeric(df['ask'], errors='coerce')\n",
    "df['bid'] = pd.to_numeric(df['bid'], errors='coerce')\n",
    "\n",
    "# set index to datetime\n",
    "df.reset_index(inplace=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "# set index to timestamp\n",
    "# df.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "# calc addl metrics\n",
    "df[\"baspread\"] = ((df.ask - df.bid) / (df.ask + df.bid) / 2).where((df.ask + df.bid) / 2 != 0)\n",
    "df['dkk_vol'] = df['adjclose'] * df['volume']\n",
    "df['zerotrade'] = np.where(df['dkk_vol'] == 0, 1, 0)\n",
    "df['ill'] = (df['stkre'].abs() / df['dkk_vol']).replace(np.inf, 0)\n",
    "df['turnover'] = df['turnover'] / df['shares']\n",
    "\n",
    "# group by ticker & month-end, aggregating stkre with max and everything else with mean\n",
    "monthly = (\n",
    "    df\n",
    "    .groupby(\n",
    "        ['ticker', pd.Grouper(key='timestamp', freq='ME')]\n",
    "    )\n",
    "    .agg(\n",
    "        volume      =('volume',   'mean'),\n",
    "        maxret      =('stkre',    'max'),\n",
    "        retvol      =('stkre',    'std'),\n",
    "        turn        =('turnover', 'mean'),\n",
    "        std_turn    =('turnover', 'std'),\n",
    "        baspread    =('baspread', 'mean'),\n",
    "        dkkvol      =('dkk_vol',  'mean'),\n",
    "        std_dkkvol  =('dkk_vol',  'std'),\n",
    "        zerotrade   =('zerotrade','mean'),\n",
    "        ill         =('ill',      'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# create 3-month rolling mean for turnover\n",
    "monthly['turn'] = monthly.groupby('ticker')['turn'].transform(lambda x: x.rolling(3).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f27d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index variance\n",
    "WINDOW = 365\n",
    "MINP = 1\n",
    "svar = omxcpi['mktre'].rolling(WINDOW, min_periods=MINP).var(ddof=0)\n",
    "svar = svar.resample('ME').last()\n",
    "# create df with market variance\n",
    "svar_df = pd.DataFrame(svar)\n",
    "# rename columns\n",
    "svar_df.columns = ['svar']\n",
    "\n",
    "monthly = monthly.merge(svar_df, on=[\"timestamp\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1cad7",
   "metadata": {},
   "source": [
    "## Metrics based on weekly series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39624f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"week\"] = df[\"timestamp\"].dt.to_period(\"W\").dt.to_timestamp(\"W-SAT\")\n",
    "mkt_ret_w = (1 + omxcpi['mktre']).resample(\"W-SAT\").prod() - 1\n",
    "\n",
    "\n",
    "# stock-level compounded weekly return\n",
    "wkret = (\n",
    "    df.groupby([\"ticker\", \"week\"])[\"stkre\"]\n",
    "      .apply(lambda x: (1 + x).prod() - 1)\n",
    "      .unstack(\"ticker\")              # rows=week, cols=ticker\n",
    "      .reindex(mkt_ret_w.index)       # align with market\n",
    ")\n",
    "\n",
    "WINDOW = 52  # reducing to 1 year from 3 years due to data availability\n",
    "MINP   = 1   # minimum number of periods for rolling calculations (first 12 months will be dropped later)\n",
    "\n",
    "# helper — same for every ticker\n",
    "mkt_var = mkt_ret_w.rolling(WINDOW, min_periods=MINP).var(ddof=0)\n",
    "\n",
    "# creat df with mkt_var and timestamp\n",
    "mkt_var_df = pd.DataFrame(mkt_var)\n",
    "mkt_var_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "betas      = {}\n",
    "idiovols   = {}\n",
    "pricedelay = {}\n",
    "\n",
    "# lagged market matrix — give the columns names 'lag0' … 'lag4'\n",
    "lagged_mkt = pd.concat(\n",
    "    [mkt_ret_w.shift(i).rename(f\"lag{i}\") for i in range(5)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# pre-compute the five lagged market series once\n",
    "market_lag = {j: mkt_ret_w.shift(j) for j in range(5)}\n",
    "\n",
    "# loop over tickers  (β, idioσ unchanged)\n",
    "for tic in wkret.columns:\n",
    "    r = wkret[tic]\n",
    "\n",
    "    # beta and betasq\n",
    "    cov  = r.rolling(WINDOW, min_periods=MINP).cov(mkt_ret_w, ddof=0)\n",
    "    beta = cov / mkt_var\n",
    "    betas[tic] = beta\n",
    "    idiovols[tic] = (r - beta * mkt_ret_w).rolling(WINDOW, min_periods=MINP).std(ddof=0)\n",
    "\n",
    "    # price-delay (Hou-Moskowitz)\n",
    "    r = wkret[tic]\n",
    "\n",
    "    # rolling corr(r, mkt lag j) for j = 0…4   ⇒   R²_j\n",
    "    r2 = [r.rolling(WINDOW, min_periods=MINP)\n",
    "            .corr(market_lag[j])\n",
    "            .pow(2)\n",
    "          for j in range(5)]\n",
    "\n",
    "    r2_sum = sum(r2)                 # R²_full  (vectorised)\n",
    "    pd_ser = 1 - r2[0] / r2_sum      # price-delay\n",
    "\n",
    "    # clean up divisions by 0 or all-NaN windows\n",
    "    pricedelay[tic] = pd_ser.where(r2_sum != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790b5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df      = pd.concat(betas,      axis=1).stack().rename(\"beta\")\n",
    "idiovol_df   = pd.concat(idiovols,   axis=1).stack().rename(\"idiovol\")\n",
    "pricedelay_df= pd.concat(pricedelay, axis=1).stack().rename(\"pricedelay\")\n",
    "\n",
    "\n",
    "weekly_panel = pd.concat([beta_df, idiovol_df, pricedelay_df], axis=1)\n",
    "weekly_panel[\"betasq\"] = weekly_panel[\"beta\"] ** 2\n",
    "\n",
    "# take the *last* weekly observation in each calendar month\n",
    "weekly_panel.index.names = [\"week\", \"ticker\"]\n",
    "week_to_month = weekly_panel.groupby([\"ticker\",\n",
    "                                      pd.Grouper(level=\"week\", freq=\"ME\")]).last()\n",
    "week_to_month = week_to_month.reset_index().rename(columns={\"week\": \"timestamp\"})\n",
    "\n",
    "monthly = monthly.merge(week_to_month, on=[\"ticker\", \"timestamp\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bc9ba",
   "metadata": {},
   "source": [
    "## Momentum metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb99251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_6515/264543020.py:18: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df_mom['adjclose'] = df_mom.groupby('ticker')['adjclose'].fillna(method='ffill')\n",
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_6515/264543020.py:18: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_mom['adjclose'] = df_mom.groupby('ticker')['adjclose'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# 1) pick only the cols we need\n",
    "df_mom = df[['timestamp','ticker','adjclose','dividend']].copy()\n",
    "\n",
    "# 2) set datetime index & monthly-end resample, grouping by ticker\n",
    "df_mom.set_index('timestamp', inplace=True)\n",
    "df_mom = (\n",
    "    df_mom\n",
    "      .groupby('ticker')\n",
    "      .resample('ME')\n",
    "      .agg({\n",
    "          'adjclose': 'last',   # last price in the month\n",
    "          'dividend': 'sum'     # total cash paid out that month\n",
    "      })\n",
    "      .rename(columns={'dividend': 'div'})\n",
    "      .fillna({'div': 0})\n",
    ")\n",
    "# carry‐forward any missing price\n",
    "df_mom['adjclose'] = df_mom.groupby('ticker')['adjclose'].fillna(method='ffill')\n",
    "df_mom = df_mom.reset_index().sort_values(['ticker','timestamp'])\n",
    "\n",
    "# 3) helper lags and rolling sums\n",
    "grp = df_mom.groupby('ticker')\n",
    "\n",
    "# price one month ago\n",
    "df_mom['price_lag1'] = grp['adjclose'].shift(1)\n",
    "# price six months ago (for 6-mo skip-one)\n",
    "df_mom['price_lag6'] = grp['adjclose'].shift(6)\n",
    "# price twelve months ago (for 12-mo skip-one)\n",
    "df_mom['price_lag12'] = grp['adjclose'].shift(12)\n",
    "\n",
    "# sum of dividends in months t-5…t-1 (5-month window, skip current)\n",
    "df_mom['div5'] = grp['div'].shift(1).rolling(window=5).sum()\n",
    "# sum of dividends in months t-11…t-1 (11-month window, skip current)\n",
    "df_mom['div11'] = grp['div'].shift(1).rolling(window=11).sum()\n",
    "\n",
    "# 4) compute total-return momentum\n",
    "\n",
    "# 1-month return including that month's dividends\n",
    "df_mom['mom1m'] = (df_mom['adjclose'] + df_mom['div']) / df_mom['price_lag1'] - 1\n",
    "\n",
    "# 6-month (5-mo skip-one): return from t-6 → t-1, including all dividends in between\n",
    "#    (price at t-1 + dividends in t-5…t-1) / price at t-6 − 1\n",
    "df_mom['mom6m'] = (df_mom['price_lag1'] + df_mom['div5']) / df_mom['price_lag6'] - 1\n",
    "\n",
    "# 12-month (11-mo skip-one): similar logic over 11-month window\n",
    "df_mom['mom12m'] = (df_mom['price_lag1'] + df_mom['div11']) / df_mom['price_lag12'] - 1\n",
    "\n",
    "# difference between the current 6-mo and the 6-mo that ended 6 months ago\n",
    "df_mom['mom7_12m'] = df_mom['mom6m'] - grp['mom6m'].shift(6)\n",
    "\n",
    "# 5) target (next month’s return)\n",
    "df_mom['target'] = grp['mom1m'].shift(-1)\n",
    "\n",
    "# 6) clean up helper cols\n",
    "df_mom = df_mom.drop(columns=[\n",
    "    'price_lag1','price_lag6','price_lag12','div5','div11'\n",
    "])\n",
    "\n",
    "# 7) merge back to your full monthly df\n",
    "monthly = monthly.merge(df_mom,on=['ticker','timestamp'],how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68ba07",
   "metadata": {},
   "source": [
    "# Add monthly OMXCPI price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9be6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "omxcpi_month = omxcpi.resample('ME').last()\n",
    "omxcpi_month.reset_index(inplace=True)\n",
    "omxcpi_month.drop(columns=['mktre'], inplace=True)\n",
    "omxcpi_month.rename(columns={'OMXCPI': 'omxcpi'}, inplace=True)\n",
    "monthly = monthly.merge(omxcpi_month, on=[\"timestamp\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6504f7",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbcd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to csv\n",
    "monthly.to_csv('../data/trade_daily.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
