{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Model Evaluation](#toc0_)\n",
    "\n",
    "This notebook contains the code to evaluate the models on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Model Evaluation](#toc1_)    \n",
    "- [Import libraries](#toc2_)    \n",
    "- [Import data](#toc3_)    \n",
    "- [Prepare data for training](#toc4_)    \n",
    "  - [Neural network data](#toc4_1_)    \n",
    "  - [Linear model data](#toc4_2_)    \n",
    "- [Train Neural Network](#toc5_)    \n",
    "  - [Graph the model](#toc5_1_)    \n",
    "- [Train linear models](#toc6_)    \n",
    "  - [OLS](#toc6_1_)    \n",
    "  - [LASSO](#toc6_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Import libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# import shap\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import TwoSlopeNorm\n",
    "# import math\n",
    "# import itertools\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from libs.models import *\n",
    "from libs.functions import *\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'figure.figsize': (10, 4), 'figure.dpi': 300})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Import data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Prepare data for training](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare expanding window splits\n",
    "periods = {\n",
    "    '21' : '2020-01-01', # 2021 is the test set\n",
    "    '22' : '2021-01-01', # 2022 is the test set\n",
    "    '23' : '2022-01-01', # 2023 is the test set\n",
    "    '24': '2023-01-01' # 2024 is the test set\n",
    "}\n",
    "\n",
    "# identify dummy vs. numeric columns\n",
    "feature_cols = [col for col in df.columns if col not in ['timestamp', 'ticker', 'target']]\n",
    "nace_cols = [c for c in feature_cols if c.startswith('NACE_')]\n",
    "dummy_cols = ['divi','divo'] # sin removed\n",
    "macro_cols = ['discount', 'tms', 'dp', 'ep', 'svar'] # 'bm_macro'\n",
    "\n",
    "# nummeric cols = cols not in cat and macro cols\n",
    "numeric_cols = [c for c in feature_cols if c not in dummy_cols and c not in nace_cols and c not in macro_cols]\n",
    "\n",
    "# feature_cols = numeric_cols + dummy_cols + nace_cols # reorder columns to have numeric first\n",
    "\n",
    "df_raw = df.copy(deep=True)\n",
    "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'])\n",
    "\n",
    "# drop data from 2025\n",
    "df_raw = df_raw[df_raw['timestamp'] < '2025-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = df[numeric_cols].values         # shape = (n_rows, P_c)\n",
    "X = df[macro_cols].values           # shape = (n_rows, P_x)\n",
    "\n",
    "# 1) compute all pairwise products with broadcasting:\n",
    "#    this gives shape (n_rows, P_c, P_x)\n",
    "K = C[:,:,None] * X[:,None,:]\n",
    "\n",
    "# 2) reshape to (n_rows, P_c * P_x)\n",
    "Z = K.reshape(len(df), -1)\n",
    "\n",
    "# 3) build the column names in the same order\n",
    "xc_names = [\n",
    "    f\"{c}_x_{m}\"\n",
    "    for c in numeric_cols\n",
    "    for m in macro_cols\n",
    "]\n",
    "\n",
    "# 4) wrap back into a DataFrame\n",
    "df_xc = pd.DataFrame(Z, columns=xc_names, index=df.index)\n",
    "\n",
    "feature_cols = numeric_cols + xc_names + dummy_cols + nace_cols\n",
    "numeric_cols = numeric_cols + xc_names\n",
    "cat_cols = dummy_cols + nace_cols\n",
    "df_z = df_raw.merge(df_xc, left_index=True, right_index=True)\n",
    "# drop macro_cols\n",
    "df_z = df_z.drop(columns=macro_cols)\n",
    "# sort columns by feature_cols\n",
    "df_norm = df_z[['timestamp', 'ticker', 'target'] + feature_cols]\n",
    "\n",
    "y_values = df_norm['target'].values.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Neural network data](#toc0_)\n",
    "Including a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare containers\n",
    "X_train, X_val, X_test = {}, {}, {}\n",
    "y_train, y_val, y_test = {}, {}, {}\n",
    "preprocessors = {}\n",
    "\n",
    "for y, period in periods.items():\n",
    "    period = pd.to_datetime(period)\n",
    "\n",
    "    # split masks\n",
    "    tr_mask = df_norm['timestamp'] < period\n",
    "    va_mask = (df_norm['timestamp'] >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=1) < period)\n",
    "    te_mask = (df_norm['timestamp'] - pd.DateOffset(years=1) >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=2) < period)\n",
    "\n",
    "    # extract raw feature DataFrames\n",
    "    X_tr_df = df_norm.loc[tr_mask, feature_cols].copy()\n",
    "    X_va_df = df_norm.loc[va_mask, feature_cols].copy()\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols].copy()\n",
    "    y_tr    = y_values[tr_mask]\n",
    "    y_va    = y_values[va_mask]\n",
    "    y_te    = y_values[te_mask]\n",
    "\n",
    "    # compute winsorization bounds on train\n",
    "    lower = X_tr_df[numeric_cols].quantile(0.01)\n",
    "    upper = X_tr_df[numeric_cols].quantile(0.99)\n",
    "\n",
    "    # apply clipping to train, val, test\n",
    "    X_tr_df[numeric_cols] = X_tr_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_va_df[numeric_cols] = X_va_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_te_df[numeric_cols] = X_te_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "\n",
    "    # now fit scaler on numeric only\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', 'passthrough',  cat_cols)\n",
    "    ])\n",
    "    preprocessor.fit(X_tr_df)\n",
    "    preprocessors[y] = preprocessor\n",
    "\n",
    "    # transform all splits\n",
    "    X_train[y] = preprocessor.transform(X_tr_df).astype('float32')\n",
    "    X_val[y]   = preprocessor.transform(X_va_df).astype('float32')\n",
    "    X_test[y]  = preprocessor.transform(X_te_df).astype('float32')\n",
    "\n",
    "    # store targets as before\n",
    "    y_train[y] = y_tr.reshape(-1, 1)\n",
    "    y_val[y]   = y_va.reshape(-1, 1)\n",
    "    y_test[y]  = y_te.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Linear model data](#toc0_)\n",
    "Excluding the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xlin_train, Xlin_test = {}, {}\n",
    "ylin_train, ylin_test = {}, {}\n",
    "preprocessors_lin = {}\n",
    "\n",
    "cat_cols_lin = cat_cols + ['const']\n",
    "feature_cols_lin = feature_cols + ['const']\n",
    "\n",
    "for y, period in periods.items():\n",
    "    period = pd.to_datetime(period)\n",
    "    tr_mask = df_norm['timestamp']- pd.DateOffset(years=1) < period\n",
    "    te_mask = (df_norm['timestamp'] - pd.DateOffset(years=1) >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=2) < period)\n",
    "\n",
    "    # extract feature DataFrames\n",
    "    X_tr_df = df_norm.loc[tr_mask, feature_cols]\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols]\n",
    "    y_tr = y_values[tr_mask]\n",
    "    y_te = y_values[te_mask]\n",
    "\n",
    "    # add constant column for linear regression\n",
    "    X_tr_df['const'] = 1\n",
    "    X_te_df['const'] = 1\n",
    "\n",
    "    # compute winsorization bounds on train\n",
    "    lower = X_tr_df[numeric_cols].quantile(0.01)\n",
    "    upper = X_tr_df[numeric_cols].quantile(0.99)\n",
    "\n",
    "    # apply clipping to train, test\n",
    "    X_tr_df[numeric_cols] = X_tr_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_te_df[numeric_cols] = X_te_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    # fit scaler only on training set\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', 'passthrough', cat_cols_lin)\n",
    "    ])\n",
    "    preprocessor.fit(X_tr_df)\n",
    "    preprocessors_lin[y] = preprocessor\n",
    "\n",
    "    # ttransform splits\n",
    "    Xlin_train[y] = preprocessor.transform(X_tr_df).astype('float32')\n",
    "    Xlin_test[y]  = preprocessor.transform(X_te_df).astype('float32')\n",
    "\n",
    "    # targets\n",
    "    ylin_train[y] = y_tr\n",
    "    ylin_test[y]  = y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Train Neural Network](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# moving to metal or CUDA GPU if available\n",
    "device = torch.device((\"cuda\" if torch.cuda.is_available() \n",
    "                       else \"mps\" if torch.backends.mps.is_available() \n",
    "                       else \"cpu\"))\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# general hyperparameters\n",
    "hidden_depth = 3 # only hidden, excluding in- and output layers\n",
    "hidden_width = 32 # int for all being equal width; list for different widths\n",
    "learning_rate = 1e-4\n",
    "activation_fun = nn.ReLU # nn.ReLU nn.Tanh nn.Sigmoid nn.LeakyReLU\n",
    "\n",
    "# general critereon and regularization parameters\n",
    "criterion = nn.MSELoss()\n",
    "lambda_l1 = 1e-3 # l1 regularization\n",
    "lambda_l2 = 1e-3 # l2 regularization\n",
    "dropout = 0.3\n",
    "\n",
    "# general parmeters\n",
    "patience = 25 # 10% of epochs\n",
    "print_freq = 250\n",
    "epochs = 250\n",
    "batch_size = 4096 # 8192 # 16384 # 2^1X adjust to your memory\n",
    "\n",
    "n_runs = 5 # number of runs for each model to average over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Year 21: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 59\n",
      "Best val loss: 1.96187E-02\n",
      "Model saved to models/mlp_y21_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 186\n",
      "Best val loss: 1.96973E-02\n",
      "Model saved to models/mlp_y21_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 160\n",
      "Best val loss: 1.97055E-02\n",
      "Model saved to models/mlp_y21_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 87\n",
      "Best val loss: 1.97042E-02\n",
      "Model saved to models/mlp_y21_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 166\n",
      "Best val loss: 1.97224E-02\n",
      "Model saved to models/mlp_y21_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run5.pth\n",
      "Averaged predictions for year 21 computed.\n",
      "\n",
      "=== Year 22: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 158\n",
      "Best val loss: 1.22011E-02\n",
      "Model saved to models/mlp_y22_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 53\n",
      "Best val loss: 1.20599E-02\n",
      "Model saved to models/mlp_y22_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 73\n",
      "Best val loss: 1.19912E-02\n",
      "Model saved to models/mlp_y22_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 34\n",
      "Best val loss: 1.19587E-02\n",
      "Model saved to models/mlp_y22_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 60\n",
      "Best val loss: 1.19742E-02\n",
      "Model saved to models/mlp_y22_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run5.pth\n",
      "Averaged predictions for year 22 computed.\n",
      "\n",
      "=== Year 23: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 133\n",
      "Best val loss: 1.00582E-01\n",
      "Model saved to models/mlp_y23_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 130\n",
      "Best val loss: 1.00793E-01\n",
      "Model saved to models/mlp_y23_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 63\n",
      "Best val loss: 1.00693E-01\n",
      "Model saved to models/mlp_y23_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 38\n",
      "Best val loss: 1.00724E-01\n",
      "Model saved to models/mlp_y23_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 95\n",
      "Best val loss: 1.00877E-01\n",
      "Model saved to models/mlp_y23_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run5.pth\n",
      "Averaged predictions for year 23 computed.\n",
      "\n",
      "=== Year 24: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 153\n",
      "Best val loss: 1.28215E-02\n",
      "Model saved to models/mlp_y24_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 64\n",
      "Best val loss: 1.28682E-02\n",
      "Model saved to models/mlp_y24_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 62\n",
      "Best val loss: 1.28642E-02\n",
      "Model saved to models/mlp_y24_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 120\n",
      "Best val loss: 1.27338E-02\n",
      "Model saved to models/mlp_y24_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 107\n",
      "Best val loss: 1.31529E-02\n",
      "Model saved to models/mlp_y24_l10.001_l20.001_drop0.3_lr0.0001_w32_d3_run5.pth\n",
      "Averaged predictions for year 24 computed.\n"
     ]
    }
   ],
   "source": [
    "best_models = {}           # you can keep one “best” model if you like (e.g. the last run)\n",
    "history   = {}\n",
    "mlp_pred  = {}\n",
    "models    = {}\n",
    "\n",
    "for y, period in periods.items():\n",
    "    print(f\"\\n=== Year {y}: running {n_runs} restarts ===\")\n",
    "    all_run_preds = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        # set random seed for reproducibility (change for each run)\n",
    "        seed = 42 + run\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        print(f\"Run {run+1}/{n_runs}, seed={seed}\")\n",
    "\n",
    "        # instantiate a fresh model & optimizer\n",
    "        input_dim = X_train[y].shape[1]\n",
    "        model = MLPModel(input_dim,\n",
    "                         depth=hidden_depth,\n",
    "                         width=hidden_width,\n",
    "                         dropout=dropout,\n",
    "                         activation=activation_fun).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=learning_rate)\n",
    "\n",
    "        # wrap datasets\n",
    "        train_ds = MLPdataset(X_train[y], y_train[y])\n",
    "        val_ds   = MLPdataset(X_val[y],   y_val[y])\n",
    "\n",
    "        # train\n",
    "        trained_model, hist = train_mlp(train_ds,\n",
    "                                        val_ds,\n",
    "                                        model,\n",
    "                                        criterion,\n",
    "                                        epochs,\n",
    "                                        patience,\n",
    "                                        print_freq,\n",
    "                                        device,\n",
    "                                        optimizer=optimizer,\n",
    "                                        lambda_l1=lambda_l1,\n",
    "                                        lambda_l2=lambda_l2,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle_train=True,\n",
    "                                        shuffle_val=False,\n",
    "                                        save_path=f'models/mlp_y{y}_l1{lambda_l1}_l2{lambda_l2}_drop{dropout}_lr{learning_rate}_w{hidden_width}_d{hidden_depth}_run{run+1}.pth'\n",
    "                                        )\n",
    "\n",
    "        # predict on test set\n",
    "        preds = predict_mlp(trained_model,\n",
    "                            X_test[y],\n",
    "                            y_test=y_test[y],\n",
    "                            scaler=preprocessors[y] if hasattr(preprocessors[y], 'inverse_transform') else None,\n",
    "                            batch_size=batch_size,\n",
    "                            device=device)\n",
    "        all_run_preds.append(preds)\n",
    "\n",
    "        # optionally store the last run’s model & history\n",
    "        best_models[(y, run)] = trained_model\n",
    "        history[(y, run)]     = hist\n",
    "\n",
    "    # stack (n_runs, n_samples) → average over axis=0\n",
    "    all_run_preds = np.stack(all_run_preds, axis=0)\n",
    "    mlp_pred[y]   = np.mean(all_run_preds, axis=0)\n",
    "\n",
    "    print(f\"Averaged predictions for year {y} computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Train linear models](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_1_'></a>[OLS](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating OLS for 21...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johan/Documents/04 Uni/10 Thesis/git/MastersThesis/libs/functions.py:192: RuntimeWarning: invalid value encountered in sqrt\n",
      "  se = np.sqrt(np.diag(cov)).reshape(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating OLS for 22...\n",
      "Estimating OLS for 23...\n",
      "Estimating OLS for 24...\n"
     ]
    }
   ],
   "source": [
    "# linear model\n",
    "# estimate the parameters\n",
    "ols_est = {}\n",
    "# ols_pred_train = {}\n",
    "ols_pred = {}\n",
    "ols_coeffs = {}\n",
    "\n",
    "\n",
    "for y in periods.keys():\n",
    "    print(f\"Estimating OLS for {y}...\")\n",
    "    x_tr = Xlin_train[y]\n",
    "    y_tr = ylin_train[y]\n",
    "    x_te = Xlin_test[y]\n",
    "    y_te = ylin_test[y]\n",
    "\n",
    "\n",
    "    # estimate the parameters\n",
    "    ols_est[y] = estimate(y_tr, x_tr)\n",
    "    # ols_pred_train[y] = ols_est[y]['b_hat'] @ x_tr.T\n",
    "    ols_pred[y] = ols_est[y]['b_hat'] @ x_te.T\n",
    "    ols_coeffs[y] = ols_est[y]['b_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roic_x_tms</th>\n",
       "      <th>roaq_x_tms</th>\n",
       "      <th>roic_x_dp</th>\n",
       "      <th>roaq_x_dp</th>\n",
       "      <th>roic_x_svar</th>\n",
       "      <th>roaq_x_svar</th>\n",
       "      <th>roaq_x_discount</th>\n",
       "      <th>roic_x_discount</th>\n",
       "      <th>roaq_x_ep</th>\n",
       "      <th>roic_x_ep</th>\n",
       "      <th>...</th>\n",
       "      <th>cashpr_x_svar</th>\n",
       "      <th>lev_x_discount</th>\n",
       "      <th>ill_x_dp</th>\n",
       "      <th>turn_x_tms</th>\n",
       "      <th>pchgm_pchsale_x_discount</th>\n",
       "      <th>pctacc_x_dp</th>\n",
       "      <th>std_turn_x_discount</th>\n",
       "      <th>cashdebt_x_tms</th>\n",
       "      <th>salecash_x_dp</th>\n",
       "      <th>rd_sale_x_svar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.506179</td>\n",
       "      <td>0.511313</td>\n",
       "      <td>0.294592</td>\n",
       "      <td>-0.286156</td>\n",
       "      <td>0.797362</td>\n",
       "      <td>-0.797641</td>\n",
       "      <td>-0.134628</td>\n",
       "      <td>0.131583</td>\n",
       "      <td>-0.315503</td>\n",
       "      <td>0.407231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>-0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.551004</td>\n",
       "      <td>0.548916</td>\n",
       "      <td>0.993486</td>\n",
       "      <td>-0.990598</td>\n",
       "      <td>-0.177860</td>\n",
       "      <td>0.178388</td>\n",
       "      <td>-0.177591</td>\n",
       "      <td>0.176125</td>\n",
       "      <td>-0.282070</td>\n",
       "      <td>0.318052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>-0.001100</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.764620</td>\n",
       "      <td>-1.768156</td>\n",
       "      <td>-2.346369</td>\n",
       "      <td>2.352144</td>\n",
       "      <td>-0.485175</td>\n",
       "      <td>0.482774</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.217865</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.086960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-2.107210</td>\n",
       "      <td>2.099086</td>\n",
       "      <td>0.302022</td>\n",
       "      <td>-0.298068</td>\n",
       "      <td>2.135682</td>\n",
       "      <td>-2.129545</td>\n",
       "      <td>2.916310</td>\n",
       "      <td>-2.908984</td>\n",
       "      <td>2.156285</td>\n",
       "      <td>-1.949453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    roic_x_tms  roaq_x_tms  roic_x_dp  roaq_x_dp  roic_x_svar  roaq_x_svar  \\\n",
       "21   -0.506179    0.511313   0.294592  -0.286156     0.797362    -0.797641   \n",
       "22   -0.551004    0.548916   0.993486  -0.990598    -0.177860     0.178388   \n",
       "23    1.764620   -1.768156  -2.346369   2.352144    -0.485175     0.482774   \n",
       "24   -2.107210    2.099086   0.302022  -0.298068     2.135682    -2.129545   \n",
       "\n",
       "    roaq_x_discount  roic_x_discount  roaq_x_ep  roic_x_ep  ...  \\\n",
       "21        -0.134628         0.131583  -0.315503   0.407231  ...   \n",
       "22        -0.177591         0.176125  -0.282070   0.318052  ...   \n",
       "23        -0.219153         0.217865   0.051667   0.086960  ...   \n",
       "24         2.916310        -2.908984   2.156285  -1.949453  ...   \n",
       "\n",
       "    cashpr_x_svar  lev_x_discount  ill_x_dp  turn_x_tms  \\\n",
       "21      -0.000562        0.000103 -0.000107    0.000454   \n",
       "22      -0.001314        0.000694 -0.001100    0.000153   \n",
       "23      -0.000564        0.001367  0.000375   -0.000221   \n",
       "24      -0.000469        0.000346  0.000848   -0.001581   \n",
       "\n",
       "    pchgm_pchsale_x_discount  pctacc_x_dp  std_turn_x_discount  \\\n",
       "21                  0.001054     0.000423             0.000326   \n",
       "22                 -0.000011     0.000763             0.000121   \n",
       "23                  0.000564     0.000505             0.000659   \n",
       "24                  0.000779     0.000264            -0.000595   \n",
       "\n",
       "    cashdebt_x_tms  salecash_x_dp  rd_sale_x_svar  \n",
       "21       -0.000426      -0.000517       -0.000433  \n",
       "22       -0.000573      -0.000382        0.000059  \n",
       "23        0.000201       0.000086       -0.000173  \n",
       "24        0.000075      -0.000030        0.000285  \n",
       "\n",
       "[4 rows x 385 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_coeffs_df = pd.DataFrame(ols_coeffs, index=feature_cols_lin)\n",
    "ols_coeffs_df = ols_coeffs_df.reindex(ols_coeffs_df.abs().sum(axis=1).sort_values(ascending=False).index, axis=0)\n",
    "ols_coeffs_df = ols_coeffs_df.T\n",
    "display(ols_coeffs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_2_'></a>[LASSO](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating LASSO for 21...\n",
      "Estimating LASSO for 22...\n",
      "Estimating LASSO for 23...\n",
      "Estimating LASSO for 24...\n"
     ]
    }
   ],
   "source": [
    "# linear model\n",
    "# create a grid using numpy.geomspace\n",
    "penalty_grid = np.geomspace(1e-7, 100, num = 1000)\n",
    "lasso_est = {}\n",
    "# lasso_pred_train = {}\n",
    "lasso_pred = {}\n",
    "lasso_coeffs = {}\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "    for y in periods.keys():\n",
    "        print(f\"Estimating LASSO for {y}...\")\n",
    "        x_tr = Xlin_train[y]\n",
    "        y_tr = ylin_train[y]\n",
    "        x_te = Xlin_test[y]\n",
    "        y_te = ylin_test[y]\n",
    "\n",
    "        # estimate the model using LassoCV\n",
    "        fit_CV = LassoCV(cv=5, alphas=penalty_grid, max_iter=1000, eps=1e-3, n_jobs=-1).fit(x_tr,y_tr)\n",
    "        # lasso_pred_train[y] = fit_CV.predict(x_tr)\n",
    "        lasso_pred[y] = fit_CV.predict(x_te)\n",
    "\n",
    "        # store the coefficients\n",
    "        coeff = fit_CV.coef_\n",
    "        lasso_coeffs[y] = coeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indmom_x_discount</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>age_x_discount</th>\n",
       "      <th>retvol_x_dp</th>\n",
       "      <th>age_x_dp</th>\n",
       "      <th>age_x_svar</th>\n",
       "      <th>indmom_x_svar</th>\n",
       "      <th>cfp_ia_x_discount</th>\n",
       "      <th>mom1m_x_discount</th>\n",
       "      <th>saleinv_x_svar</th>\n",
       "      <th>...</th>\n",
       "      <th>turn_x_discount</th>\n",
       "      <th>pchsale_pchinvt_x_dp</th>\n",
       "      <th>rd_x_tms</th>\n",
       "      <th>chatoia_x_svar</th>\n",
       "      <th>std_turn_x_tms</th>\n",
       "      <th>invest_x_svar</th>\n",
       "      <th>pricedelay_x_tms</th>\n",
       "      <th>acc_x_tms</th>\n",
       "      <th>mom12m_x_svar</th>\n",
       "      <th>dy_x_svar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>-0.011049</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.005509</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>-0.005822</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.011855</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>-0.011579</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>-0.004986</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>-0.005752</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>-0.003968</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>-0.004049</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>-0.003508</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.003292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    indmom_x_discount    mom12m  age_x_discount  retvol_x_dp  age_x_dp  \\\n",
       "21           0.011941  0.008003       -0.011049     0.004804 -0.005509   \n",
       "22           0.011855  0.008319       -0.011579     0.005688 -0.004986   \n",
       "23           0.010299  0.007802       -0.006855     0.006583 -0.003968   \n",
       "24           0.009636  0.007448       -0.000604     0.006724 -0.005943   \n",
       "\n",
       "    age_x_svar  indmom_x_svar  cfp_ia_x_discount  mom1m_x_discount  \\\n",
       "21    0.005513      -0.005822           0.003619          0.003745   \n",
       "22    0.005956      -0.005752           0.003973          0.003462   \n",
       "23    0.004533      -0.004049           0.004941          0.003819   \n",
       "24    0.004270      -0.003508           0.005565          0.004731   \n",
       "\n",
       "    saleinv_x_svar  ...  turn_x_discount  pchsale_pchinvt_x_dp  rd_x_tms  \\\n",
       "21        0.003560  ...        -0.000176             -0.000000 -0.000097   \n",
       "22        0.003766  ...        -0.000130             -0.000121 -0.000016   \n",
       "23        0.003208  ...        -0.000000             -0.000000 -0.000000   \n",
       "24        0.003292  ...        -0.000000             -0.000180 -0.000185   \n",
       "\n",
       "    chatoia_x_svar  std_turn_x_tms  invest_x_svar  pricedelay_x_tms  \\\n",
       "21        0.000151       -0.000046      -0.000115          0.000000   \n",
       "22        0.000077       -0.000045      -0.000000          0.000000   \n",
       "23        0.000000       -0.000136      -0.000000          0.000094   \n",
       "24        0.000000       -0.000000      -0.000000          0.000000   \n",
       "\n",
       "    acc_x_tms  mom12m_x_svar  dy_x_svar  \n",
       "21   -0.00000      -0.000000   0.000000  \n",
       "22   -0.00000      -0.000000   0.000000  \n",
       "23   -0.00000      -0.000000   0.000004  \n",
       "24   -0.00007      -0.000064   0.000000  \n",
       "\n",
       "[4 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_coeffs_df = pd.DataFrame(lasso_coeffs, index=feature_cols_lin)\n",
    "# sort by absolute value\n",
    "lasso_coeffs_df = lasso_coeffs_df.reindex(lasso_coeffs_df.abs().sum(axis=1).sort_values(ascending=False).index, axis=0)\n",
    "\n",
    "# drop columns with all zeros\n",
    "lasso_coeffs_df = lasso_coeffs_df.T\n",
    "lasso_coeffs_df = lasso_coeffs_df.loc[:, (lasso_coeffs_df != 0).any(axis=0)]\n",
    "display(lasso_coeffs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = []\n",
    "\n",
    "for y, period in periods.items():\n",
    "    # rebuild masks\n",
    "    te_mask = ((df_norm['timestamp'] - pd.DateOffset(years=1) >= period) &\n",
    "               (df_norm['timestamp'] - pd.DateOffset(years=2) <  period))\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols]\n",
    "    idx = X_te_df.index\n",
    "\n",
    "\n",
    "    pred_dfs.append(pd.DataFrame({\n",
    "        'period':    y,\n",
    "        'timestamp': df_norm.loc[idx, 'timestamp'],\n",
    "        'ticker':    df_norm.loc[idx, 'ticker'],\n",
    "        'y_true':    df_norm.loc[idx, 'target'].values.astype('float32'),\n",
    "        'OLS':    ols_pred[y].flatten(),\n",
    "        'LASSO':  lasso_pred[y],\n",
    "        'MLP':    mlp_pred[y],\n",
    "    }, index=idx))\n",
    "\n",
    "all_preds = pd.concat(pred_dfs).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lccc}\n",
      "\\hline\\hline \\\\ [-1.8ex]\n",
      " & OLS & LASSO & MLP \\\\ \n",
      " \\hline \n",
      "RMSE & 0.20040 & 0.19532 & 0.19463 \\\\ \n",
      "MAE & 0.08743 & 0.07925 & 0.07743 \\\\ \n",
      "\\hline\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "methods = ['OLS', \n",
    "           'LASSO', \n",
    "           'MLP',\n",
    "           ]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    rmse = rmse_fun(all_preds[method], all_preds['y_true'])\n",
    "    mae = mae_fun(all_preds[method], all_preds['y_true'])\n",
    "    results[method] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae\n",
    "    }\n",
    "\n",
    "metrics = {}\n",
    "for metric in ['RMSE','MAE']:\n",
    "    key = f'{metric}'\n",
    "    vals = [\n",
    "        results['OLS'][metric],\n",
    "        results['LASSO'][metric],\n",
    "        results['MLP'][metric],\n",
    "        ]\n",
    "    metrics[key] = vals\n",
    "\n",
    "tab = latex_table(methods,metrics)\n",
    "\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{clccc}\n",
      "\\hline\\hline \\\\ [-1.8ex]\n",
      " &  & OLS & LASSO & MLP \\\\ \n",
      " \\hline \n",
      "\\multirow[c]{4}{*}{\\rotatebox{90}{RMSE}}& 2021 & 0.11697 & 0.10895 & 0.10968 \\\\ \n",
      " & 2022 & 0.32097 & 0.31817 & 0.31748 \\\\ \n",
      " & 2023 & 0.12683 & 0.11483 & 0.11352 \\\\ \n",
      " & 2024 & 0.16596 & 0.16129 & 0.15963 \\\\ \n",
      "\\hline\\multirow[c]{4}{*}{\\rotatebox{90}{MAE}}& 2021 & 0.08267 & 0.07238 & 0.07204 \\\\ \n",
      " & 2022 & 0.10512 & 0.10074 & 0.09741 \\\\ \n",
      " & 2023 & 0.08146 & 0.06964 & 0.06835 \\\\ \n",
      " & 2024 & 0.08019 & 0.07404 & 0.07164 \\\\ \n",
      "\\hline\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "metrics_full = {}\n",
    "results_full = {}\n",
    "for y, period in periods.items():\n",
    "    for method in methods:\n",
    "        y_true = all_preds.loc[all_preds['period'] == y, 'y_true']\n",
    "        y_pred = all_preds.loc[all_preds['period'] == y, method]\n",
    "        key = f'{method}{y}'\n",
    "        results_full[key] = {\n",
    "            'RMSE': rmse_fun(y_pred, y_true),\n",
    "            'MAE': mae_fun(y_pred, y_true)\n",
    "        }\n",
    "    \n",
    "    for metric in ['RMSE','MAE']:\n",
    "        key = f'*{metric}*20{y}'\n",
    "        vals = [\n",
    "            results_full[f'OLS{y}'][metric],\n",
    "            results_full[f'LASSO{y}'][metric],\n",
    "            results_full[f'MLP{y}'][metric],\n",
    "        ]\n",
    "        metrics_full[key] = vals\n",
    "\n",
    "tab_full = latex_table_grouped(methods,metrics_full)\n",
    "\n",
    "print(tab_full)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
