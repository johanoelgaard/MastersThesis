{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Model Evaluation](#toc0_)\n",
    "\n",
    "This notebook contains the code to evaluate the models on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Model Evaluation](#toc1_)    \n",
    "- [Import libraries](#toc2_)    \n",
    "- [Import data](#toc3_)    \n",
    "- [Prepare data for training](#toc4_)    \n",
    "  - [Neural network data](#toc4_1_)    \n",
    "  - [Linear model data](#toc4_2_)    \n",
    "- [Train Neural Network](#toc5_)    \n",
    "  - [Constant width](#toc5_1_)    \n",
    "  - [Pyramid](#toc5_2_)    \n",
    "- [Train linear models](#toc6_)    \n",
    "  - [OLS](#toc6_1_)    \n",
    "  - [LASSO](#toc6_2_)    \n",
    "  - [Naïve](#toc6_3_)    \n",
    "- [Summarize the results](#toc7_)    \n",
    "  - [Variable importance](#toc7_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Import libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from collections import defaultdict\n",
    "\n",
    "from libs.models import *\n",
    "from libs.functions import *\n",
    "\n",
    "plt.rcParams.update({'font.size': 12, 'figure.figsize': (10, 4), 'figure.dpi': 300})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Import data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Prepare data for training](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: 53\n",
      "Dummy columns: 2\n",
      "NACE columns: 52\n",
      "Macro columns: 5\n"
     ]
    }
   ],
   "source": [
    "# prepare expanding window splits\n",
    "periods = {\n",
    "    '21' : '2019-12-31', # 2021 is the test set\n",
    "    '22' : '2020-12-31', # 2022 is the test set\n",
    "    '23' : '2021-12-31', # 2023 is the test set\n",
    "    '24': '2022-12-31' # 2024 is the test set\n",
    "}\n",
    "\n",
    "# identify dummy vs. numeric columns\n",
    "feature_cols = [col for col in df.columns if col not in ['timestamp', 'ticker', 'target']]\n",
    "nace_cols = [c for c in feature_cols if c.startswith('NACE_')]\n",
    "dummy_cols = ['divi','divo'] # sin removed\n",
    "macro_cols = ['discount', 'tms', 'dp', 'ep', 'svar'] # 'bm_macro'\n",
    "\n",
    "# nummeric cols = cols not in cat and macro cols\n",
    "numeric_cols = [c for c in feature_cols if c not in dummy_cols and c not in nace_cols and c not in macro_cols]\n",
    "print(f'Numeric columns: {len(numeric_cols)}')\n",
    "print(f'Dummy columns: {len(dummy_cols)}')\n",
    "print(f'NACE columns: {len(nace_cols)}')\n",
    "print(f'Macro columns: {len(macro_cols)}')\n",
    "\n",
    "# feature_cols = numeric_cols + dummy_cols + nace_cols # reorder columns to have numeric first\n",
    "\n",
    "df_raw = df.copy(deep=True)\n",
    "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'])\n",
    "\n",
    "# drop data from 2025\n",
    "df_raw = df_raw[df_raw['timestamp'] < '2024-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_cols: 372\n"
     ]
    }
   ],
   "source": [
    "C = df[numeric_cols].values         # shape = (n_rows, P_c)\n",
    "X = df[macro_cols].values           # shape = (n_rows, P_x)\n",
    "\n",
    "# 1) compute all pairwise products with broadcasting:\n",
    "#    this gives shape (n_rows, P_c, P_x)\n",
    "K = C[:,:,None] * X[:,None,:]\n",
    "\n",
    "# 2) reshape to (n_rows, P_c * P_x)\n",
    "Z = K.reshape(len(df), -1)\n",
    "\n",
    "# 3) build the column names in the same order\n",
    "xc_names = [\n",
    "    f\"{c}_x_{m}\"\n",
    "    for c in numeric_cols\n",
    "    for m in macro_cols\n",
    "]\n",
    "\n",
    "# 4) wrap back into a DataFrame\n",
    "df_xc = pd.DataFrame(Z, columns=xc_names, index=df.index)\n",
    "\n",
    "feature_cols = numeric_cols + xc_names + dummy_cols + nace_cols\n",
    "numeric_cols = numeric_cols + xc_names\n",
    "cat_cols = dummy_cols + nace_cols\n",
    "df_z = df_raw.merge(df_xc, left_index=True, right_index=True)\n",
    "# drop macro_cols\n",
    "df_z = df_z.drop(columns=macro_cols)\n",
    "# sort columns by feature_cols\n",
    "df_norm = df_z[['timestamp', 'ticker', 'target'] + feature_cols]\n",
    "\n",
    "y_values = df_norm['target'].values.astype('float32')\n",
    "print(f'feature_cols: {len(feature_cols)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Neural network data](#toc0_)\n",
    "Including a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare containers\n",
    "X_train, X_val, X_test = {}, {}, {}\n",
    "y_train, y_val, y_test = {}, {}, {}\n",
    "preprocessors = {}\n",
    "y_scalers = {}\n",
    "\n",
    "for y, period in periods.items():\n",
    "    period = pd.to_datetime(period)\n",
    "\n",
    "    # split masks\n",
    "    tr_mask = df_norm['timestamp'] < period\n",
    "    va_mask = (df_norm['timestamp'] >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=1) < period)\n",
    "    te_mask = (df_norm['timestamp'] - pd.DateOffset(years=1) >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=2) < period)\n",
    "\n",
    "    # extract raw feature DataFrames\n",
    "    X_tr_df = df_norm.loc[tr_mask, feature_cols].copy()\n",
    "    X_va_df = df_norm.loc[va_mask, feature_cols].copy()\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols].copy()\n",
    "    y_tr    = y_values[tr_mask]\n",
    "    y_va    = y_values[va_mask]\n",
    "    y_te    = y_values[te_mask]\n",
    "\n",
    "    # compute winsorization bounds on train\n",
    "    lower = X_tr_df[numeric_cols].quantile(0.01)\n",
    "    upper = X_tr_df[numeric_cols].quantile(0.99)\n",
    "\n",
    "    # apply clipping to train, val, test\n",
    "    X_tr_df[numeric_cols] = X_tr_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_va_df[numeric_cols] = X_va_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_te_df[numeric_cols] = X_te_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    # now fit scaler on numeric only\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', 'passthrough',  cat_cols)\n",
    "    ])\n",
    "    preprocessor.fit(X_tr_df)\n",
    "    preprocessors[y] = preprocessor\n",
    "\n",
    "    # transform all splits\n",
    "    X_train[y] = preprocessor.transform(X_tr_df).astype('float32')\n",
    "    X_val[y]   = preprocessor.transform(X_va_df).astype('float32')\n",
    "    X_test[y]  = preprocessor.transform(X_te_df).astype('float32')\n",
    "\n",
    "    # fit standard scaler on y values\n",
    "    y_scaler = StandardScaler()\n",
    "    y_scaler.fit(y_tr.reshape(-1, 1))\n",
    "    y_scalers[y] = y_scaler\n",
    "    y_tr = y_scaler.transform(y_tr.reshape(-1, 1)).flatten()\n",
    "    y_va = y_scaler.transform(y_va.reshape(-1, 1)).flatten()\n",
    "    y_te = y_scaler.transform(y_te.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # store targets as before\n",
    "    y_train[y] = y_tr.reshape(-1, 1)\n",
    "    y_val[y]   = y_va.reshape(-1, 1)\n",
    "    y_test[y]  = y_te.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Linear model data](#toc0_)\n",
    "Excluding the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xlin_train, Xlin_test = {}, {}\n",
    "ylin_train, ylin_test = {}, {}\n",
    "preprocessors_lin = {}\n",
    "\n",
    "cat_cols_lin = cat_cols + ['const']\n",
    "feature_cols_lin = feature_cols + ['const']\n",
    "\n",
    "for y, period in periods.items():\n",
    "    period = pd.to_datetime(period)\n",
    "    tr_mask = df_norm['timestamp']- pd.DateOffset(years=1) < period\n",
    "    te_mask = (df_norm['timestamp'] - pd.DateOffset(years=1) >= period) & \\\n",
    "              (df_norm['timestamp'] - pd.DateOffset(years=2) < period)\n",
    "\n",
    "    # extract feature DataFrames\n",
    "    X_tr_df = df_norm.loc[tr_mask, feature_cols]\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols]\n",
    "    y_tr = y_values[tr_mask]\n",
    "    y_te = y_values[te_mask]\n",
    "\n",
    "    # add constant column for linear regression\n",
    "    X_tr_df['const'] = 1\n",
    "    X_te_df['const'] = 1\n",
    "\n",
    "    # compute winsorization bounds on train\n",
    "    lower = X_tr_df[numeric_cols].quantile(0.01)\n",
    "    upper = X_tr_df[numeric_cols].quantile(0.99)\n",
    "\n",
    "    # apply clipping to train, test\n",
    "    X_tr_df[numeric_cols] = X_tr_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "    X_te_df[numeric_cols] = X_te_df[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    # fit scaler only on training set\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', 'passthrough', cat_cols_lin)\n",
    "    ])\n",
    "    preprocessor.fit(X_tr_df)\n",
    "    preprocessors_lin[y] = preprocessor\n",
    "\n",
    "    # ttransform splits\n",
    "    Xlin_train[y] = preprocessor.transform(X_tr_df).astype('float32')\n",
    "    Xlin_test[y]  = preprocessor.transform(X_te_df).astype('float32')\n",
    "\n",
    "    # targets\n",
    "    ylin_train[y] = y_tr\n",
    "    ylin_test[y]  = y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Train Neural Network](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_1_'></a>[Constant width](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# moving to metal or CUDA GPU if available\n",
    "device = torch.device((\"cuda\" if torch.cuda.is_available() \n",
    "                       else \"mps\" if torch.backends.mps.is_available() \n",
    "                       else \"cpu\"))\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# general hyperparameters\n",
    "hidden_depth = 2 # only hidden, excluding in- and output layers\n",
    "hidden_width = 64 # int for all being equal width; list for different widths\n",
    "learning_rate = 5e-5 # 1e-4 # 1e-5\n",
    "activation_fun = nn.ReLU # nn.ReLU nn.Tanh nn.Sigmoid nn.LeakyReLU\n",
    "\n",
    "# general critereon and regularization parameters\n",
    "criterion = nn.MSELoss() # nn.HuberLoss()\n",
    "lambda_l1 = 1e-4 # 1e-5 # 1e-4 # l1 regularization\n",
    "lambda_l2 = 1e-3 # 1e-4 # 1e-3 # l2 regularization\n",
    "dropout = 0.0\n",
    "\n",
    "# general parmeters\n",
    "patience = 25\n",
    "print_freq = 250\n",
    "epochs = 250\n",
    "batch_size = 4096\n",
    "\n",
    "n_runs = 5 # number of runs for each model to average over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Year 21: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 72\n",
      "Best val loss: 1.13764E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 26\n",
      "Best val loss: 1.13273E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 223\n",
      "Best val loss: 1.12180E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 26\n",
      "Best val loss: 1.13586E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 66\n",
      "Best val loss: 1.13169E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run5.pth\n",
      "Averaged predictions for year 21 computed.\n",
      "\n",
      "=== Year 22: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 62\n",
      "Best val loss: 7.01680E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 64\n",
      "Best val loss: 7.02948E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 54\n",
      "Best val loss: 7.03056E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 85\n",
      "Best val loss: 7.02792E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 40\n",
      "Best val loss: 7.05170E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run5.pth\n",
      "Averaged predictions for year 22 computed.\n",
      "\n",
      "=== Year 23: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 26\n",
      "Best val loss: 9.54538E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 34\n",
      "Best val loss: 9.72893E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 27\n",
      "Best val loss: 9.51737E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 33\n",
      "Best val loss: 9.69359E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 29\n",
      "Best val loss: 9.72075E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run5.pth\n",
      "Averaged predictions for year 23 computed.\n",
      "\n",
      "=== Year 24: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 31\n",
      "Best val loss: 7.13006E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 61\n",
      "Best val loss: 7.10399E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 40\n",
      "Best val loss: 7.12646E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 50\n",
      "Best val loss: 7.11196E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 36\n",
      "Best val loss: 7.15626E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w64_d2_run5.pth\n",
      "Averaged predictions for year 24 computed.\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "history   = {}\n",
    "mlp_pred  = {}\n",
    "\n",
    "for y, period in periods.items():\n",
    "    print(f\"\\n=== Year {y}: running {n_runs} restarts ===\")\n",
    "    all_run_preds = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        # set random seed for reproducibility (change for each run)\n",
    "        seed = 42 + run\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        print(f\"Run {run+1}/{n_runs}, seed={seed}\")\n",
    "\n",
    "        # instantiate a fresh model & optimizer\n",
    "        input_dim = X_train[y].shape[1]\n",
    "        model = MLPModel(input_dim,\n",
    "                         depth=hidden_depth,\n",
    "                         width=hidden_width,\n",
    "                         dropout=dropout,\n",
    "                         activation=activation_fun).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=learning_rate)\n",
    "\n",
    "\n",
    "        # wrap datasets\n",
    "        train_ds = MLPdataset(X_train[y], y_train[y])\n",
    "        val_ds   = MLPdataset(X_val[y],   y_val[y])\n",
    "\n",
    "        # train\n",
    "        trained_model, hist = train_mlp(train_ds,\n",
    "                                        val_ds,\n",
    "                                        model,\n",
    "                                        criterion,\n",
    "                                        epochs,\n",
    "                                        patience,\n",
    "                                        print_freq,\n",
    "                                        device,\n",
    "                                        optimizer=optimizer,\n",
    "                                        lambda_l1=lambda_l1,\n",
    "                                        lambda_l2=lambda_l2,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle_train=True,\n",
    "                                        shuffle_val=False,\n",
    "                                        save_path=f'models/mlp_y{y}_l1{lambda_l1}_l2{lambda_l2}_drop{dropout}_lr{learning_rate}_w{hidden_width}_d{hidden_depth}_run{run+1}.pth'\n",
    "                                        )\n",
    "\n",
    "        # predict on test set\n",
    "        preds = predict_mlp(trained_model,\n",
    "                            X_test[y],\n",
    "                            y_test=y_test[y],\n",
    "                            scaler= y_scalers[y],\n",
    "                            batch_size=batch_size,\n",
    "                            device=device)\n",
    "        all_run_preds.append(preds)\n",
    "\n",
    "        # optionally store the last run’s model & history\n",
    "        best_models[(y, run)] = trained_model\n",
    "        history[(y, run)]     = hist\n",
    "\n",
    "    # stack (n_runs, n_samples) average over axis=0\n",
    "    all_run_preds = np.stack(all_run_preds, axis=0)\n",
    "    mlp_pred[y]   = np.mean(all_run_preds, axis=0)\n",
    "\n",
    "    print(f\"Averaged predictions for year {y} computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_2_'></a>[Pyramid](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model with most data on multiple parameters\n",
    "hidden_depth_pyr = None\n",
    "hidden_width_pyr = [32, 16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Year 21: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 80\n",
      "Best val loss: 1.12889E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 85\n",
      "Best val loss: 1.13973E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 159\n",
      "Best val loss: 1.14440E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Epoch 250/250  - Train Loss: 9.56915E-01  - Val Loss: 1.13825E+00\n",
      "Best val loss: 1.13782E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 101\n",
      "Best val loss: 1.12726E+00\n",
      "Model saved to models/mlp_y21_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run5.pth\n",
      "Averaged predictions for year 21 computed.\n",
      "\n",
      "=== Year 22: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 72\n",
      "Best val loss: 7.09817E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 109\n",
      "Best val loss: 7.06356E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 178\n",
      "Best val loss: 7.03017E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 115\n",
      "Best val loss: 6.98806E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 248\n",
      "Best val loss: 7.06312E-01\n",
      "Model saved to models/mlp_y22_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run5.pth\n",
      "Averaged predictions for year 22 computed.\n",
      "\n",
      "=== Year 23: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 181\n",
      "Best val loss: 9.71252E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 26\n",
      "Best val loss: 9.63187E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 27\n",
      "Best val loss: 9.45904E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 48\n",
      "Best val loss: 9.43455E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 240\n",
      "Best val loss: 9.68983E-01\n",
      "Model saved to models/mlp_y23_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run5.pth\n",
      "Averaged predictions for year 23 computed.\n",
      "\n",
      "=== Year 24: running 5 restarts ===\n",
      "Run 1/5, seed=42\n",
      "Early stopping at epoch 208\n",
      "Best val loss: 7.13186E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run1.pth\n",
      "Run 2/5, seed=43\n",
      "Early stopping at epoch 52\n",
      "Best val loss: 7.03887E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run2.pth\n",
      "Run 3/5, seed=44\n",
      "Early stopping at epoch 46\n",
      "Best val loss: 7.07279E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run3.pth\n",
      "Run 4/5, seed=45\n",
      "Early stopping at epoch 61\n",
      "Best val loss: 7.16970E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run4.pth\n",
      "Run 5/5, seed=46\n",
      "Early stopping at epoch 114\n",
      "Best val loss: 7.09568E-01\n",
      "Model saved to models/mlp_y24_l10.0001_l20.001_drop0.0_lr5e-05_w[32, 16, 8]_d3_run5.pth\n",
      "Averaged predictions for year 24 computed.\n"
     ]
    }
   ],
   "source": [
    "best_models_pyr = {}\n",
    "history_pyr   = {}\n",
    "mlp_pred_pyr  = {}\n",
    "\n",
    "for y, period in periods.items():\n",
    "    print(f\"\\n=== Year {y}: running {n_runs} restarts ===\")\n",
    "    all_run_preds = []\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        # set random seed for reproducibility (change for each run)\n",
    "        seed = 42 + run\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        print(f\"Run {run+1}/{n_runs}, seed={seed}\")\n",
    "\n",
    "        # instantiate a fresh model & optimizer\n",
    "        input_dim = X_train[y].shape[1]\n",
    "        model = MLPModel(input_dim,\n",
    "                         depth=len(hidden_width_pyr),\n",
    "                         width=hidden_width_pyr,\n",
    "                         dropout=dropout,\n",
    "                         activation=activation_fun).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                      lr=learning_rate)\n",
    "\n",
    "\n",
    "        # wrap datasets\n",
    "        train_ds = MLPdataset(X_train[y], y_train[y])\n",
    "        val_ds   = MLPdataset(X_val[y],   y_val[y])\n",
    "\n",
    "        # train\n",
    "        trained_model, hist = train_mlp(train_ds,\n",
    "                                        val_ds,\n",
    "                                        model,\n",
    "                                        criterion,\n",
    "                                        epochs,\n",
    "                                        patience,\n",
    "                                        print_freq,\n",
    "                                        device,\n",
    "                                        optimizer=optimizer,\n",
    "                                        lambda_l1=lambda_l1,\n",
    "                                        lambda_l2=lambda_l2,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle_train=True,\n",
    "                                        shuffle_val=False,\n",
    "                                        save_path=f'models/mlp_y{y}_l1{lambda_l1}_l2{lambda_l2}_drop{dropout}_lr{learning_rate}_w{hidden_width_pyr}_d{len(hidden_width_pyr)}_run{run+1}.pth'\n",
    "                                        )\n",
    "\n",
    "        # predict on test set\n",
    "        preds = predict_mlp(trained_model,\n",
    "                            X_test[y],\n",
    "                            y_test=y_test[y],\n",
    "                            scaler= y_scalers[y], # preprocessors[y] if hasattr(preprocessors[y], 'inverse_transform') else None,\n",
    "                            batch_size=batch_size,\n",
    "                            device=device)\n",
    "        all_run_preds.append(preds)\n",
    "\n",
    "        # optionally store the last run’s model & history\n",
    "        best_models_pyr[(y, run)] = trained_model\n",
    "        history_pyr[(y, run)]     = hist\n",
    "\n",
    "    # stack (n_runs, n_samples) average over axis=0\n",
    "    all_run_preds = np.stack(all_run_preds, axis=0)\n",
    "    mlp_pred_pyr[y] = np.mean(all_run_preds, axis=0)\n",
    "\n",
    "    print(f\"Averaged predictions for year {y} computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Train linear models](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_1_'></a>[OLS](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating OLS for 21...\n",
      "Estimating OLS for 22...\n",
      "Estimating OLS for 23...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johan/Documents/04 Uni/10 Thesis/git/MastersThesis/libs/functions.py:197: RuntimeWarning: invalid value encountered in sqrt\n",
      "  se = np.sqrt(np.diag(cov)).reshape(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating OLS for 24...\n"
     ]
    }
   ],
   "source": [
    "# linear model\n",
    "# estimate the parameters\n",
    "ols_est = {}\n",
    "ols_pred = {}\n",
    "ols_coefs = {}\n",
    "\n",
    "\n",
    "for y in periods.keys():\n",
    "    print(f\"Estimating OLS for {y}...\")\n",
    "    x_tr = Xlin_train[y]\n",
    "    y_tr = ylin_train[y]\n",
    "    x_te = Xlin_test[y]\n",
    "    y_te = ylin_test[y]\n",
    "\n",
    "\n",
    "    # estimate the parameters\n",
    "    ols_est[y] = estimate(y_tr, x_tr)\n",
    "    # ols_pred_train[y] = ols_est[y]['b_hat'] @ x_tr.T\n",
    "    ols_pred[y] = ols_est[y]['b_hat'] @ x_te.T\n",
    "    ols_coefs[y] = ols_est[y]['b_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_coefs_df = pd.DataFrame(ols_coefs, index=feature_cols_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_2_'></a>[LASSO](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating LASSO for 21...\n",
      "Estimating LASSO for 22...\n",
      "Estimating LASSO for 23...\n",
      "Estimating LASSO for 24...\n"
     ]
    }
   ],
   "source": [
    "# linear model\n",
    "# create a grid using numpy.geomspace\n",
    "penalty_grid = np.geomspace(1e-7, 100, num = 1000)\n",
    "lasso_est = {}\n",
    "# lasso_pred_train = {}\n",
    "lasso_pred = {}\n",
    "lasso_coefs = {}\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "    for y in periods.keys():\n",
    "        print(f\"Estimating LASSO for {y}...\")\n",
    "        x_tr = Xlin_train[y]\n",
    "        y_tr = ylin_train[y]\n",
    "        x_te = Xlin_test[y]\n",
    "        y_te = ylin_test[y]\n",
    "\n",
    "        # estimate the model using LassoCV\n",
    "        fit_CV = LassoCV(cv=5, alphas=penalty_grid, max_iter=1000, eps=1e-3, n_jobs=-1).fit(x_tr,y_tr)\n",
    "        # lasso_pred_train[y] = fit_CV.predict(x_tr)\n",
    "        lasso_pred[y] = fit_CV.predict(x_te)\n",
    "\n",
    "        # store the coefficients\n",
    "        coef = fit_CV.coef_\n",
    "        lasso_coefs[y] = coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs_df = pd.DataFrame(lasso_coefs, index=feature_cols_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_3_'></a>[Naïve](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_pred = {}\n",
    "\n",
    "for y in periods.keys():\n",
    "    # naive prediction is the mean of the training set\n",
    "    pred = np.mean(ylin_train[y])\n",
    "    naive_pred[y] = np.full_like(ylin_test[y], pred, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Summarize the results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = []\n",
    "\n",
    "for y, period in periods.items():\n",
    "    # rebuild masks\n",
    "    te_mask = ((df_norm['timestamp'] - pd.DateOffset(years=1) >= period) &\n",
    "               (df_norm['timestamp'] - pd.DateOffset(years=2) <  period))\n",
    "    X_te_df = df_norm.loc[te_mask, feature_cols]\n",
    "    idx = X_te_df.index\n",
    "\n",
    "\n",
    "    pred_dfs.append(pd.DataFrame({\n",
    "        'period':    y,\n",
    "        'timestamp': df_norm.loc[idx, 'timestamp'],\n",
    "        'ticker':    df_norm.loc[idx, 'ticker'],\n",
    "        'y_true':    df_norm.loc[idx, 'target'].values.astype('float32'),\n",
    "        # 'discount':  df.loc[idx, 'discount'].values.astype('float32'),\n",
    "        'Naïve':  naive_pred[y],\n",
    "        'OLS':    ols_pred[y].flatten(),\n",
    "        'LASSO':  lasso_pred[y],\n",
    "        'MLP':    mlp_pred[y],\n",
    "        'MLP-Pyr': mlp_pred_pyr[y],\n",
    "    }, index=idx))\n",
    "\n",
    "all_preds = pd.concat(pred_dfs).sort_index()\n",
    "\n",
    "# save predictions\n",
    "all_preds.to_csv('data/predictions.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{clccccc}\n",
      "\\hline\\hline \\\\ [-1.8ex]\n",
      " &  & Naïve & OLS & LASSO & MLP & MLP-Pyr \\\\ \n",
      " \\hline \n",
      "\\multirow[c]{5}{*}{\\rotatebox{90}{RMSE}} \n",
      "& 2021 & 0.10729 & 0.11147 & 0.10598 & 0.10619 & 0.10609 \\\\ \n",
      " & 2022 & 0.12309 & 0.12599 & 0.12419 & 0.12432 & 0.12443 \\\\ \n",
      " & 2023 & 0.10608 & 0.11413 & 0.10856 & 0.10608 & 0.10552 \\\\ \n",
      " & 2024 & 0.10975 & 0.11445 & 0.11169 & 0.10949 & 0.10948 \\\\ \n",
      " & Total & 0.11177 & 0.11664 & 0.11281 & 0.11179 & 0.11166 \\\\ \n",
      "\\hline\\multirow[c]{5}{*}{\\rotatebox{90}{MAE}} \n",
      "& 2021 & 0.06921 & 0.07593 & 0.06953 & 0.06903 & 0.06882 \\\\ \n",
      " & 2022 & 0.08553 & 0.08749 & 0.08727 & 0.08722 & 0.08747 \\\\ \n",
      " & 2023 & 0.06752 & 0.07352 & 0.06862 & 0.06718 & 0.06636 \\\\ \n",
      " & 2024 & 0.06864 & 0.07467 & 0.07103 & 0.06856 & 0.06843 \\\\ \n",
      " & Total & 0.07277 & 0.07794 & 0.07414 & 0.07304 & 0.07282 \\\\ \n",
      "\\hline\\multirow[c]{5}{*}{\\rotatebox{90}{AMADL}} \n",
      "& 2021 & -0.00444 & 0.00084 & -0.00484 & -0.00481 & -0.00452 \\\\ \n",
      " & 2022 & 0.01058 & 0.01002 & 0.01000 & 0.01100 & 0.00980 \\\\ \n",
      " & 2023 & 0.00543 & 0.00605 & 0.00521 & 0.00606 & 0.00269 \\\\ \n",
      " & 2024 & 0.00389 & 0.00620 & 0.00617 & 0.00372 & 0.00424 \\\\ \n",
      " & Total & 0.00380 & 0.00574 & 0.00405 & 0.00393 & 0.00299 \\\\ \n",
      "\\hline\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "all_preds = pd.read_csv('data/predictions.csv', index_col=0, parse_dates=['timestamp'])\n",
    "all_preds['period'] = all_preds['period'].astype('string')\n",
    "\n",
    "metrics_full = {}\n",
    "results_full = {}\n",
    "methods = ['Naïve',\n",
    "           'OLS', \n",
    "           'LASSO', \n",
    "           'MLP',\n",
    "           'MLP-Pyr',\n",
    "           ]\n",
    "for method in methods:\n",
    "    for y, period in periods.items():\n",
    "        y_true = all_preds.loc[all_preds['period'] == y, 'y_true']\n",
    "        y_pred = all_preds.loc[all_preds['period'] == y, method]\n",
    "        key = f'{method}{y}'\n",
    "        results_full[key] = {\n",
    "            'RMSE': rmse_fun(y_pred, y_true),\n",
    "            'MAE': mae_fun(y_pred, y_true),\n",
    "            # 'MADL': madl_fun(y_pred, y_true),\n",
    "            'AMADL': amadl_fun(y_pred, y_true, delta=0.5)\n",
    "        }\n",
    "    key = f'{method}Total'\n",
    "    results_full[key] = {\n",
    "        'RMSE': rmse_fun(all_preds[method], all_preds['y_true']),\n",
    "        'MAE': mae_fun(all_preds[method], all_preds['y_true']),\n",
    "        # 'MADL': madl_fun(all_preds[method], all_preds['y_true']),\n",
    "        'AMADL' : amadl_fun(all_preds[method], all_preds['y_true'], delta=0.5)\n",
    "    }\n",
    "    \n",
    "for y in list(periods.keys()) + ['Total']:\n",
    "    if y != 'Total':\n",
    "        name = '20' + y\n",
    "    else:\n",
    "        name = y\n",
    "    for metric in ['RMSE',\n",
    "                   'MAE',\n",
    "                #    'MADL',\n",
    "                   'AMADL']:\n",
    "        key = f'*{metric}*{name}'\n",
    "        vals = [\n",
    "            results_full[f'Naïve{y}'][metric],\n",
    "            results_full[f'OLS{y}'][metric],\n",
    "            results_full[f'LASSO{y}'][metric],\n",
    "            results_full[f'MLP{y}'][metric],\n",
    "            results_full[f'MLP-Pyr{y}'][metric],\n",
    "        ]\n",
    "        metrics_full[key] = vals\n",
    "\n",
    "tab_full = latex_table_grouped(methods,metrics_full)\n",
    "\n",
    "with open('tabs/prediction_results.tex', 'w') as f:\n",
    "    f.write(tab_full)\n",
    "# print(tab_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc7_1_'></a>[Variable importance](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_order   = list(periods.keys())             # ['21','22','23','24']\n",
    "run_order      = list(range(n_runs))              # [0,1,2]\n",
    "\n",
    "imp_by_model_year = defaultdict(list)\n",
    "\n",
    "# ols and lasso\n",
    "for y in period_order:\n",
    "    X_eval, y_eval = Xlin_test[y], ylin_test[y].flatten()\n",
    "\n",
    "    beta_ols    = ols_coefs_df[y].loc[feature_cols_lin].values\n",
    "    beta_lasso  = lasso_coefs_df[y].loc[feature_cols_lin].values \n",
    "\n",
    "    imp_by_model_year['OLS'].append(\n",
    "        importance_lin(beta_ols, X_eval, y_eval, const='const', \n",
    "                       feature=feature_cols_lin)\n",
    "    )\n",
    "    imp_by_model_year['LASSO'].append(\n",
    "        importance_lin(beta_lasso, X_eval, y_eval, const='const', \n",
    "                       feature=feature_cols_lin)\n",
    "    )\n",
    "\n",
    "# constant width mlp\n",
    "for y in period_order:\n",
    "    X_eval, y_eval = X_test[y], y_test[y].flatten()\n",
    "\n",
    "    # mean across runs first\n",
    "    imp_runs = []\n",
    "    for r in run_order:\n",
    "        model = best_models[(y, r)]\n",
    "        imp_runs.append(importance_nn(model, X_eval, y_eval, device))\n",
    "    imp_by_model_year['MLP'].append( np.mean(imp_runs, axis=0) )\n",
    "\n",
    "# pyramid model\n",
    "for y in period_order:\n",
    "    X_eval, y_eval = X_test[y], y_test[y].flatten()\n",
    "\n",
    "    imp_runs = []\n",
    "    for r in run_order:\n",
    "        model = best_models_pyr[(y, r)]\n",
    "        imp_runs.append(importance_nn(model, X_eval, y_eval, device))\n",
    "    imp_by_model_year['MLP-Pyr'].append( np.mean(imp_runs, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_by_model = {\n",
    "    m : np.mean(vectors, axis=0)           # arithmetic mean over years\n",
    "    for m, vectors in imp_by_model_year.items()\n",
    "}\n",
    "\n",
    "# build a single DataFrame  (rows = features, cols = models)\n",
    "imp_df = pd.DataFrame(\n",
    "    { m : vec for m, vec in imp_by_model.items() },\n",
    "    index = feature_cols\n",
    ")\n",
    "\n",
    "base_names = pd.Series(imp_df.index).map(group_label).values\n",
    "imp_df_agg = (\n",
    "    imp_df\n",
    "      .assign(base = base_names)\n",
    "      .groupby('base', sort=False)\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "# optional: order rows by overall importance\n",
    "imp_df_agg = imp_df_agg.loc[\n",
    "    imp_df_agg[['LASSO','MLP']].mean(axis=1).sort_values(ascending=False).index\n",
    "]\n",
    "\n",
    "# sort by ranking\n",
    "imp_df_agg = imp_df_agg.loc[imp_df_agg[['LASSO','MLP']].rank(axis=0, method='max', ascending=False).mean(axis=1).sort_values(ascending=True).index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(1.5*len(imp_df_agg.columns),\n",
    "                                0.2*len(imp_df_agg)))\n",
    "\n",
    "im = ax.imshow(imp_df_agg.values, aspect='auto', cmap='Blues', vmin=0, vmax=.04)\n",
    "ax.set_xticks(np.arange(len(imp_df_agg.columns)))\n",
    "ax.set_xticklabels(imp_df_agg.columns, ha='center')\n",
    "ax.set_yticks(np.arange(len(imp_df_agg.index)))\n",
    "ax.set_yticklabels(imp_df_agg.index, fontsize=10)\n",
    "\n",
    "# cbar = fig.colorbar(im, ax=ax, fraction=0.02, pad=0.02)\n",
    "# cbar.ax.set_ylabel(\"Normalised $\\Delta$MSE\",\n",
    "#                    rotation=-90, va='bottom')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('figs/variable_importance.png', bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the (year,run) lists\n",
    "years    = ['21','22','23','24']\n",
    "runs     = list(range(n_runs))\n",
    "\n",
    "mlp_runs     = [(y,r) for y in years for r in runs]\n",
    "pyr_runs     = [(y,r) for y in years for r in runs]\n",
    "\n",
    "# ensemble curve for any PyTorch dict\n",
    "def ensemble_pytorch_curve(model_dict, \n",
    "                                    j,            # feature-index\n",
    "                                    grid,         # array of std-scaled X values\n",
    "                                    device):\n",
    "    P     = len(feature_cols)\n",
    "    G     = len(grid)\n",
    "    Xg    = np.zeros((G,P), dtype=np.float32)\n",
    "    Xg[:,j] = grid\n",
    "    Xt    = torch.tensor(Xg, dtype=torch.float32, device=device)\n",
    "\n",
    "    all_curves = []\n",
    "    for y,r in (mlp_runs if model_dict is best_models else pyr_runs):\n",
    "        m = model_dict[(y,r)]\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            zhat = m(Xt).cpu().numpy().flatten()\n",
    "            z0   = m(torch.zeros((1,P),dtype=torch.float32,device=device)).item()\n",
    "\n",
    "        # invert to raw % returns\n",
    "        raw   = y_scalers[y].inverse_transform(zhat.reshape(-1,1)).flatten()*100\n",
    "        base0 = y_scalers[y].inverse_transform([[z0]]).flatten()[0]*100\n",
    "\n",
    "        all_curves.append(raw - base0)\n",
    "\n",
    "    return np.stack(all_curves,axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# use a +- 1 std grid\n",
    "grid = np.linspace(-1, 1, 200)\n",
    "\n",
    "features_to_plot = ['mvel1','gma','maxret','mom12m']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (ax, feat) in enumerate(zip(axes, features_to_plot)):\n",
    "    j = feature_cols.index(feat)\n",
    "\n",
    "    # MLP\n",
    "    c_mlp = ensemble_pytorch_curve(best_models, j, grid, device)\n",
    "    ax.plot(grid, c_mlp,      label='MLP',   lw=2)\n",
    "\n",
    "    # MLP-Pyr\n",
    "    c_pyr = ensemble_pytorch_curve(best_models_pyr, j, grid, device)\n",
    "    ax.plot(grid, c_pyr,      label='MLP-Pyr', ls='--')\n",
    "\n",
    "    ax.axhline(0, color='k', lw=0.5, alpha=0.5)\n",
    "    ax.set_title(feat)\n",
    "    ax.set_xlabel(f\"{feat} (std.)\")\n",
    "    ax.grid(True, ls=':', lw=0.4)\n",
    "    if i < 2:\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "axes[0].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[2].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[0].legend(loc='upper left', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/feature_curves.png', bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature curves for all features\n",
    "grid           = np.linspace(-1, 1, 200)   # +-1 σ grid\n",
    "n_cols, n_rows = 3, 5\n",
    "per_fig        = n_cols * n_rows           # 15 panels per page\n",
    "\n",
    "\n",
    "# drop interactions (\"_x_\") and NACE and other dummies\n",
    "plot_features = sorted(\n",
    "    f for f in feature_cols\n",
    "    if \"_x_\" not in f and not f.startswith(\"NACE_\") and not f.startswith(\"divi\") and not f.startswith(\"divo\")\n",
    "    )\n",
    "\n",
    "# pre-compute mapping from feature name to col index\n",
    "fidx = {f: i for i, f in enumerate(feature_cols)}\n",
    "\n",
    "\n",
    "# page loop\n",
    "for page, start in enumerate(range(0, len(plot_features), per_fig), 1):\n",
    "    feats = plot_features[start : start + per_fig]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(n_cols * 3.5, n_rows * 2.625),\n",
    "        sharey=True\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "    for ax in axes:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    for k, feat in enumerate(feats):\n",
    "        ax = axes[k]\n",
    "        ax.set_visible(True)\n",
    "        j  = fidx[feat]\n",
    "\n",
    "        # compute marginal‐effect curves\n",
    "        c_mlp = ensemble_pytorch_curve(best_models,     j, grid, device)\n",
    "        c_pyr = ensemble_pytorch_curve(best_models_pyr, j, grid, device)\n",
    "\n",
    "        ax.plot(grid, c_mlp,      lw=1.5, label=\"MLP\")\n",
    "        ax.plot(grid, c_pyr, ls=\"--\", lw=1.0, label=\"MLP-pyr\")\n",
    "        ax.axhline(0, color=\"k\", lw=0.5, alpha=0.4)\n",
    "\n",
    "        ax.set_title(feat)\n",
    "        ax.set_xlabel(f\"{feat} (std.)\")\n",
    "        ax.grid(True, ls=\":\", lw=0.3)\n",
    "\n",
    "        # only bottom row shows x-tick labels\n",
    "        if k // n_cols != n_rows - 1:\n",
    "            ax.tick_params(axis=\"x\", labelbottom=False)\n",
    "        # only first column shows y-label\n",
    "        if k % n_cols == 0:\n",
    "            ax.set_ylabel(r\"$\\Delta$ Excess return (%)\")\n",
    "\n",
    "    axes[0].legend(fontsize=8, loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outfile = f\"figs/feature_curves_page{page:02d}.png\"\n",
    "    plt.savefig(outfile, dpi=300, bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the ensemble\n",
    "cross_feat = 'mvel1'\n",
    "\n",
    "j_cross_feat  = feature_cols.index(cross_feat)\n",
    "\n",
    "# plot panels\n",
    "features_to_plot = ['idiovol','gma','maxret', 'mom12m']\n",
    "grid     = np.linspace(-1, 1, 200)       # your rank-normalised range\n",
    "fixed_ls = [-1, -0.5, 0, 0.5, 1]         # curves for these mvel1-values\n",
    "colors   = plt.cm.viridis(np.linspace(0,1,len(fixed_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "years    = ['21','22','23','24']\n",
    "runs     = list(range(n_runs))         # e.g. [0,1,2,3,4]\n",
    "mlp_runs = [(y,r) for y in years for r in runs]\n",
    "P        = len(feature_cols)\n",
    "\n",
    "# precompute the raw-return baseline at X=0 for every (year,run)\n",
    "baseline = {}\n",
    "zero_X   = torch.zeros((1,P), dtype=torch.float32, device=device)\n",
    "for y, r in mlp_runs:\n",
    "    m = best_models[(y,r)]\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        z0 = m(zero_X).item()                    # in z-space\n",
    "    # invert and scale to percent\n",
    "    raw0 = y_scalers[y].inverse_transform([[z0]]).flatten()[0] * 100\n",
    "    baseline[(y,r)] = raw0\n",
    "\n",
    "def ensemble_interaction_curve(j_feat, j_cross_feat, fixed_mvel1, grid, mlpruns, best_models):\n",
    "    \"\"\"\n",
    "    j_feat       : index of the swept-out feature (mom1m, mom12m, etc.)\n",
    "    fixed_mvel1  : one of [-1, -0.5, 0, 0.5, 1]\n",
    "    grid         : array of std-scaled values for that feature\n",
    "    \"\"\"\n",
    "    G = len(grid)\n",
    "    Xg = np.zeros((G, P), dtype=np.float32)\n",
    "    Xg[:, j_cross_feat] = fixed_mvel1\n",
    "    Xg[:, j_feat]  = grid\n",
    "    Xt = torch.tensor(Xg, dtype=torch.float32, device=device)\n",
    "\n",
    "    all_preds = []\n",
    "    for y, r in mlpruns:\n",
    "        m = best_models[(y, r)]\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            zhat = m(Xt).cpu().numpy().flatten()    # (G,) in z-space\n",
    "\n",
    "        # invert to raw % returns\n",
    "        raw = (y_scalers[y]\n",
    "               .inverse_transform(zhat.reshape(-1,1))\n",
    "               .flatten()) * 100\n",
    "\n",
    "        # center by the precomputed baseline\n",
    "        all_preds.append(raw - baseline[(y,r)])\n",
    "\n",
    "    return np.stack(all_preds, axis=0).mean(axis=0)  # avg over (year,run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,8), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (ax, feat) in enumerate(zip(axes, features_to_plot)):\n",
    "    j_feat = feature_cols.index(feat)\n",
    "\n",
    "    for v, color in zip(fixed_ls, colors):\n",
    "        curve = ensemble_interaction_curve(j_feat, j_cross_feat, v, grid, mlp_runs, best_models)\n",
    "        ax.plot(grid, curve, label=f\"{cross_feat}={v}\", color=color)\n",
    "\n",
    "    ax.axhline(0, color='k', lw=0.5, alpha=0.5)\n",
    "    ax.set_title(f\"{cross_feat} $\\\\times$ {feat}\")\n",
    "    ax.set_xlabel(f\"{feat} (std.)\")\n",
    "    ax.grid(True, ls=':', lw=0.4)\n",
    "    if i < 2:\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "axes[0].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[2].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[0].legend(title=f\"Fixed {cross_feat}\", fontsize=12, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/interaction_curves.png', bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "years    = ['21','22','23','24']\n",
    "runs     = list(range(n_runs))       \n",
    "pyr_runs = [(y,r) for y in years for r in runs]\n",
    "\n",
    "# precompute the raw-return baseline at X=0 for every (year,run)\n",
    "baseline = {}\n",
    "zero_X   = torch.zeros((1,P), dtype=torch.float32, device=device)\n",
    "for y, r in pyr_runs:\n",
    "    m = best_models_pyr[(y,r)]\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        z0 = m(zero_X).item()                    # in z-space\n",
    "    # invert and scale to percent\n",
    "    raw0 = y_scalers[y].inverse_transform([[z0]]).flatten()[0] * 100\n",
    "    baseline[(y,r)] = raw0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,8), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (ax, feat) in enumerate(zip(axes, features_to_plot)):\n",
    "    j_feat = feature_cols.index(feat)\n",
    "\n",
    "    for v, color in zip(fixed_ls, colors):\n",
    "        curve = ensemble_interaction_curve(j_feat, j_cross_feat, v, grid, pyr_runs, best_models_pyr)\n",
    "        ax.plot(grid, curve, label=f\"{cross_feat}={v}\", color=color)\n",
    "\n",
    "    ax.axhline(0, color='k', lw=0.5, alpha=0.5)\n",
    "    ax.set_title(f\"{cross_feat} $\\\\times$ {feat}\")\n",
    "    ax.set_xlabel(f\"{feat} (std.)\")\n",
    "    ax.grid(True, ls=':', lw=0.4)\n",
    "    if i < 2:\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "axes[0].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[2].set_ylabel(\"$\\Delta$ Excess return (%)\")\n",
    "axes[0].legend(title=f\"Fixed {cross_feat}\", fontsize=12, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/interaction_curves_pyr.png', bbox_inches='tight')\n",
    "# plt.show()\n",
    "plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
