{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76e3a1",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba903c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "path = '/Users/johan/Library/CloudStorage/GoogleDrive-johan.oelgaard@gmail.com/My Drive/04 Økonomi/10 Thesis/Data'\n",
    "\n",
    "# read daily market data from eikon\n",
    "daily = 'eikon_daily.xlsx'\n",
    "eikon_dfs = pd.read_excel(path + '/' + daily, sheet_name=None)\n",
    "eikon_keys = eikon_dfs.keys()\n",
    "\n",
    "monthly = 'eikon_monthly.xlsx'\n",
    "eikon_divi = pd.read_excel(path + '/' + monthly, sheet_name='Dividend', header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc99d5",
   "metadata": {},
   "source": [
    "# Load in trading data and dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97852e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set first row as header\n",
    "divi = eikon_divi.iloc[:,1:].copy()\n",
    "divi.rename(columns={'Unnamed: 1': 'ticker', 'Date': 'announcement timestamp', 'Dividend Pay Date': 'timestamp', 'Adjusted Gross Dividend Amount': 'adjdivi gross', 'Adjusted Net Dividend Amount': 'adjdivi net'}, inplace=True)\n",
    "\n",
    "# if net dividend is not available, use gross dividend\n",
    "divi['adjdivi net'] = divi['adjdivi net'].fillna(divi['adjdivi gross'])\n",
    "divi['timestamp'] = divi['timestamp'].fillna(divi['announcement timestamp'])\n",
    "\n",
    "divi['timestamp'] = pd.to_datetime(divi['timestamp'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "# drop other columns\n",
    "divi = divi[['ticker', 'timestamp', 'adjdivi net']]\n",
    "divi = divi.rename(columns={'adjdivi net': 'dividend'})\n",
    "\n",
    "# drop na\n",
    "divi = divi.dropna().reset_index(drop=True)\n",
    "divi.set_index('timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a40ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# load trade data\n",
    "trade_values_df = eikon_dfs['Trade Values'].iloc[:,1:]\n",
    "# set up multi-index for the columns\n",
    "trade_values_df.columns = pd.MultiIndex.from_arrays(trade_values_df.iloc[:2].values)\n",
    "# drop the first two rows as they are now headers\n",
    "trade_values_df = trade_values_df.iloc[2:].reset_index(drop=True)\n",
    "# set the first column as index\n",
    "trade_values_df.set_index(trade_values_df.columns[0], inplace=True)\n",
    "trade_values_df.index.name = \"timestamp\"\n",
    "trade_values_df = trade_values_df.sort_index(axis=1, level=0)\n",
    "# keep only trade close values\n",
    "trade_values_df = trade_values_df.loc[:, (slice(None), ['Trade Close','Trade Volume'])]\n",
    "# set 0 values to NaN\n",
    "trade_values_df = trade_values_df.replace(0, np.nan)\n",
    "\n",
    "# backward fill the data for each ticker\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# loop over the tickers that are actually in the df\n",
    "for ticker in trade_values_df.columns.get_level_values(0).unique():\n",
    "    # extract the sub-dataframe for this ticker using .loc with IndexSlice\n",
    "    subdf = trade_values_df.loc[:, idx[ticker, :]]\n",
    "    \n",
    "    # find the index range where the ticker has any valid data\n",
    "    valid_idx = subdf.dropna(how='all').index\n",
    "\n",
    "    # use backward fill in the date range\n",
    "    trade_values_df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]] = trade_values_df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]].bfill()\n",
    "\n",
    "# stack first level of columns to rows\n",
    "trade_values_df = trade_values_df.stack(level=0,future_stack=True).reset_index()\n",
    "trade_values_df = trade_values_df.dropna()\n",
    "# rename columns\n",
    "trade_values_df.columns = ['timestamp', 'ticker', 'adjclose', 'volume']\n",
    "# set first column as index\n",
    "trade_values_df.set_index('timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181297ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dividend data\n",
    "trade_values_df = trade_values_df.merge(divi, how='left', on=['ticker', 'timestamp'])\n",
    "# set dividend to 0 na\n",
    "trade_values_df['dividend'] = trade_values_df['dividend'].fillna(0)\n",
    "\n",
    "trade_values_df['adjclose_divi'] = trade_values_df['adjclose'] + trade_values_df['dividend']\n",
    "\n",
    "# calculate the daily returns\n",
    "trade_values_df = trade_values_df.sort_values(by=['ticker', 'timestamp'], ascending=[True, True])\n",
    "trade_values_df['stkre'] = trade_values_df.groupby('ticker', group_keys=False)['adjclose_divi'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176a56f",
   "metadata": {},
   "source": [
    "# Load index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355cf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# load index data\n",
    "omxcpi = eikon_dfs['OMXCPI'].iloc[:,1:]\n",
    "# set first row as header\n",
    "omxcpi.columns = omxcpi.iloc[0]\n",
    "# drop the first row as it is now header\n",
    "omxcpi = omxcpi.iloc[1:].reset_index(drop=True)\n",
    "# set the first column as index\n",
    "omxcpi.set_index(omxcpi.columns[0], inplace=True)\n",
    "omxcpi.index.name = \"timestamp\"\n",
    "omxcpi = omxcpi.sort_index(axis=1)\n",
    "# keep only closing values\n",
    "omxcpi = omxcpi.loc[:,'Trade Close']\n",
    "# convert to dataframe\n",
    "omxcpi = pd.DataFrame(omxcpi)\n",
    "# rename columns\n",
    "omxcpi.columns = ['OMXCPI']\n",
    "\n",
    "omxcpi = omxcpi.sort_index(ascending=True)\n",
    "omxcpi['mktre'] = omxcpi['OMXCPI'].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126f3ca",
   "metadata": {},
   "source": [
    "# Calculate beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78fb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate the rolling beta\n",
    "# # join the two dataframes on index\n",
    "# beta = trade_values_df.join(omxcpi, how='left')\n",
    "# # drop Trade Close and OMXCPI columns and calculate beta\n",
    "# beta = beta.drop(columns=['adjclose', 'volume', 'OMXCPI', 'adjclose_divi', 'dividend']).dropna()\n",
    "# beta = beta.groupby('ticker').apply(rolling_beta, include_groups=False)\n",
    "\n",
    "# # create df\n",
    "# beta = beta.reset_index()\n",
    "# beta.columns = ['ticker', 'timestamp', 'beta']\n",
    "# # set the index to timestamp\n",
    "# beta.set_index('timestamp', inplace=True)\n",
    "\n",
    "# # save the beta to csv\n",
    "# beta.to_csv('data/beta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018037c",
   "metadata": {},
   "source": [
    "# Load additional trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a67cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "turnover_df = eikon_dfs['Turnover'].iloc[:,1:]\n",
    "ask_df = eikon_dfs['Ask'].iloc[:,1:]\n",
    "bid_df = eikon_dfs['Bid'].iloc[:,1:]\n",
    "\n",
    "\n",
    "turnover_df.columns = pd.MultiIndex.from_arrays(turnover_df.iloc[:2].values)\n",
    "turnover_df = turnover_df.iloc[2:].reset_index(drop=True)\n",
    "turnover_df.set_index(turnover_df.columns[0], inplace=True)\n",
    "turnover_df.index.name = \"timestamp\"  \n",
    "\n",
    "ask_df.columns = pd.MultiIndex.from_arrays(ask_df.iloc[:2].values)\n",
    "ask_df = ask_df.iloc[2:].reset_index(drop=True)\n",
    "ask_df.set_index(ask_df.columns[0], inplace=True)\n",
    "ask_df.index.name = \"timestamp\"\n",
    "\n",
    "bid_df.columns = pd.MultiIndex.from_arrays(bid_df.iloc[:2].values)\n",
    "bid_df = bid_df.iloc[2:].reset_index(drop=True)\n",
    "bid_df.set_index(bid_df.columns[0], inplace=True)\n",
    "bid_df.index.name = \"timestamp\"\n",
    "\n",
    "\n",
    "turnover_df = turnover_df.stack(level=0, future_stack=True).reset_index().set_index('timestamp')\n",
    "turnover_df.drop(columns=['TRNOVR_UNS'], inplace=True)\n",
    "# turnover_df.dropna(inplace=True)\n",
    "turnover_df.columns = ['ticker', 'turnover']\n",
    "\n",
    "ask_df = ask_df.stack(level=0, future_stack=True).reset_index().set_index('timestamp')\n",
    "ask_df.drop(columns=['ASK'], inplace=True)\n",
    "# ask_df.dropna(inplace=True)\n",
    "ask_df.columns = [ 'ticker', 'ask']\n",
    "\n",
    "bid_df = bid_df.stack(level=0,future_stack=True).reset_index().set_index('timestamp')\n",
    "bid_df.drop(columns=['BID'], inplace=True)\n",
    "# bid_df.dropna(inplace=True)\n",
    "bid_df.columns = ['ticker', 'bid']\n",
    "\n",
    "# merge w. trade values on index and ticker\n",
    "# df = trade_values_df.reset_index()\n",
    "df = trade_values_df.copy()\n",
    "df = df.merge(turnover_df, on=['timestamp', 'ticker'], how='left')\n",
    "df = df.merge(ask_df, on=['timestamp', 'ticker'], how='left')\n",
    "df = df.merge(bid_df, on=['timestamp', 'ticker'], how='left')\n",
    "\n",
    "# prerequisites -------------------------------------------------------------\n",
    "df = df.sort_values(['ticker', 'timestamp'])         # already have the right order\n",
    "cols_to_ffill = ['turnover', 'ask', 'bid']           # numeric columns to fill\n",
    "\n",
    "# Identify where row have *any* real data?\n",
    "has_val = df[cols_to_ffill].notna().any(axis=1)      # boolean Series, same length as df\n",
    "\n",
    "#     Inside every ticker, mark rows that lie *after* the first real data point, AND *before* the last real data point.\n",
    "g = df['ticker']                                     # short alias\n",
    "\n",
    "# cummax() of True/False gives a running “ever seen True so far?”\n",
    "left_ok  = has_val.groupby(g).cummax()               # after (or at) 1st real value\n",
    "right_ok = has_val.iloc[::-1].groupby(g.iloc[::-1]) \\\n",
    "                        .cummax().iloc[::-1]         # before (or at) last real value\n",
    "\n",
    "mask = left_ok & right_ok                            # True only inside the window\n",
    "\n",
    "# compute a forward fill *inside each ticker* once\n",
    "filled = df.groupby(g, group_keys=False)[cols_to_ffill].ffill()\n",
    "\n",
    "# put the filled numbers back, but **only** where `mask` is True\n",
    "df.loc[mask, cols_to_ffill] = filled.loc[mask]\n",
    "\n",
    "# optionally get rid of rows that are still all-NaN\n",
    "df.dropna(subset=cols_to_ffill, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018b757",
   "metadata": {},
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables to numeric\n",
    "df['adjclose'] = pd.to_numeric(df['adjclose'], errors='coerce')\n",
    "df['volume'] = pd.to_numeric(df['volume'], errors='coerce')\n",
    "df['stkre'] = pd.to_numeric(df['stkre'], errors='coerce')\n",
    "df['turnover'] = pd.to_numeric(df['turnover'], errors='coerce')\n",
    "df['ask'] = pd.to_numeric(df['ask'], errors='coerce')\n",
    "df['bid'] = pd.to_numeric(df['bid'], errors='coerce')\n",
    "\n",
    "# set index to datetime\n",
    "df.reset_index(inplace=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "# set index to timestamp\n",
    "# df.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "# calc addl metrics\n",
    "df[\"baspread\"] = ((df.ask - df.bid) / (df.ask + df.bid) / 2).where((df.ask + df.bid) / 2 != 0)\n",
    "df['dkk_vol'] = df['adjclose'] * df['volume']\n",
    "df['zerotrade'] = np.where(df['dkk_vol'] == 0, 1, 0)\n",
    "df['ill'] = (df['stkre'].abs() / df['dkk_vol']).replace(np.inf, 0)\n",
    "\n",
    "# group by ticker & month-end, aggregating stkre with max and everything else with mean\n",
    "monthly = (\n",
    "    df\n",
    "    .groupby(\n",
    "        ['ticker', pd.Grouper(key='timestamp', freq='ME')]\n",
    "    )\n",
    "    .agg(\n",
    "        volume      =('volume',   'mean'),\n",
    "        maxret      =('stkre',    'max'),\n",
    "        retvol      =('stkre',    'std'),\n",
    "        turn        =('turnover','mean'),\n",
    "        std_turn    =('turnover','std'),\n",
    "        baspread    =('baspread','mean'),\n",
    "        dkkvol      =('dkk_vol',  'mean'),\n",
    "        std_dkkvol  =('dkk_vol',  'std'),\n",
    "        zerotrade   =('zerotrade','mean'),\n",
    "        ill         =('ill',      'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f27d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_58336/896120531.py:5: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  svar = svar.resample('M').last()\n"
     ]
    }
   ],
   "source": [
    "# index variance\n",
    "WINDOW = 365\n",
    "MINP = 1\n",
    "svar = omxcpi['mktre'].rolling(WINDOW, min_periods=MINP).var(ddof=0)\n",
    "svar = svar.resample('M').last()\n",
    "# create df with market variance\n",
    "svar_df = pd.DataFrame(svar)\n",
    "# rename columns\n",
    "svar_df.columns = ['svar']\n",
    "\n",
    "monthly = monthly.merge(svar_df, on=[\"timestamp\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1cad7",
   "metadata": {},
   "source": [
    "## Metrics based on weekly series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39624f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"week\"] = df[\"timestamp\"].dt.to_period(\"W\").dt.to_timestamp(\"W-SAT\")\n",
    "mkt_ret_w = (1 + omxcpi['mktre']).resample(\"W-SAT\").prod() - 1\n",
    "\n",
    "\n",
    "# stock-level compounded weekly return\n",
    "wkret = (\n",
    "    df.groupby([\"ticker\", \"week\"])[\"stkre\"]\n",
    "      .apply(lambda x: (1 + x).prod() - 1)\n",
    "      .unstack(\"ticker\")              # rows=week, cols=ticker\n",
    "      .reindex(mkt_ret_w.index)       # align with market\n",
    ")\n",
    "\n",
    "WINDOW = 52  # reducing to 1 year from 3 years due to data availability\n",
    "MINP   = 1   # minimum number of periods for rolling calculations (first 12 months will be dropped later)\n",
    "\n",
    "# helper — same for every ticker\n",
    "mkt_var = mkt_ret_w.rolling(WINDOW, min_periods=MINP).var(ddof=0)\n",
    "\n",
    "# creat df with mkt_var and timestamp\n",
    "mkt_var_df = pd.DataFrame(mkt_var)\n",
    "mkt_var_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "betas      = {}\n",
    "idiovols   = {}\n",
    "pricedelay = {}\n",
    "\n",
    "# lagged market matrix — give the columns names 'lag0' … 'lag4'\n",
    "lagged_mkt = pd.concat(\n",
    "    [mkt_ret_w.shift(i).rename(f\"lag{i}\") for i in range(5)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# pre-compute the five lagged market series once\n",
    "market_lag = {j: mkt_ret_w.shift(j) for j in range(5)}\n",
    "\n",
    "# loop over tickers  (β, idioσ unchanged)\n",
    "for tic in wkret.columns:\n",
    "    r = wkret[tic]\n",
    "\n",
    "    # beta and betasq\n",
    "    cov  = r.rolling(WINDOW, min_periods=MINP).cov(mkt_ret_w, ddof=0)\n",
    "    beta = cov / mkt_var\n",
    "    betas[tic] = beta\n",
    "    idiovols[tic] = (r - beta * mkt_ret_w).rolling(WINDOW, min_periods=MINP).std(ddof=0)\n",
    "\n",
    "    # price-delay (Hou-Moskowitz)\n",
    "    r = wkret[tic]\n",
    "\n",
    "    # rolling corr(r, mkt lag j) for j = 0…4   ⇒   R²_j\n",
    "    r2 = [r.rolling(WINDOW, min_periods=MINP)\n",
    "            .corr(market_lag[j])\n",
    "            .pow(2)\n",
    "          for j in range(5)]\n",
    "\n",
    "    r2_sum = sum(r2)                 # R²_full  (vectorised)\n",
    "    pd_ser = 1 - r2[0] / r2_sum      # price-delay\n",
    "\n",
    "    # clean up divisions by 0 or all-NaN windows\n",
    "    pricedelay[tic] = pd_ser.where(r2_sum != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790b5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df      = pd.concat(betas,      axis=1).stack().rename(\"beta\")\n",
    "idiovol_df   = pd.concat(idiovols,   axis=1).stack().rename(\"idiovol\")\n",
    "pricedelay_df= pd.concat(pricedelay, axis=1).stack().rename(\"pricedelay\")\n",
    "\n",
    "\n",
    "weekly_panel = pd.concat([beta_df, idiovol_df, pricedelay_df], axis=1)\n",
    "weekly_panel[\"betasq\"] = weekly_panel[\"beta\"] ** 2\n",
    "\n",
    "# take the *last* weekly observation in each calendar month\n",
    "weekly_panel.index.names = [\"week\", \"ticker\"]\n",
    "week_to_month = weekly_panel.groupby([\"ticker\",\n",
    "                                      pd.Grouper(level=\"week\", freq=\"ME\")]).last()\n",
    "week_to_month = week_to_month.reset_index().rename(columns={\"week\": \"timestamp\"})\n",
    "\n",
    "monthly = monthly.merge(week_to_month, on=[\"ticker\", \"timestamp\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bc9ba",
   "metadata": {},
   "source": [
    "## Momentum metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb371e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"] = df[\"timestamp\"].dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "\n",
    "mret = (\n",
    "    1 + df.groupby([\"ticker\", \"month\"])[\"stkre\"]\n",
    "          .apply(lambda x: (1 + x).prod() - 1)    # daily ⇒ monthly\n",
    ")\n",
    "mret.index = mret.index.set_names([\"ticker\", \"month\"])\n",
    "\n",
    "g = mret.groupby(level=0, group_keys=False)                # group by ticker only\n",
    "\n",
    "# momentum variables\n",
    "mom1m  = mret                             .rename(\"mom1m\")   # month t-1\n",
    "mom6m  = g.apply(cumret, 6, 2)            .rename(\"mom6m\")   # t-2 … t-6\n",
    "mom12m = g.apply(cumret, 12, 2)           .rename(\"mom12m\")  # t-2 … t-12\n",
    "mom7_12m = g.apply(cumret,12,7)          .rename(\"mom7_12m\") # t-7 … t-12\n",
    "# mom36m = g.apply(cumret, 36, 13)          .rename(\"mom36m\")  # t-13 … t-36 # removing this for now\n",
    "\n",
    "# df for merge\n",
    "momentum = (\n",
    "    pd.concat([mom1m, mom6m, mom12m, mom7_12m], axis=1)   # guaranteed same index\n",
    "      .reset_index()\n",
    "      .rename(columns={\"month\": \"timestamp\"})\n",
    ")\n",
    "\n",
    "# merge\n",
    "monthly = monthly.merge(momentum, on=[\"ticker\", \"timestamp\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6504f7",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dbcd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to csv\n",
    "monthly.to_csv('data/trade_daily.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
