{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to data\n",
    "path_market = '/Users/johan/Library/CloudStorage/GoogleDrive-johan.oelgaard@gmail.com/My Drive/04 Økonomi/10 Thesis/Data'\n",
    "# path_finacials = '/Users/johan/Library/CloudStorage/GoogleDrive-johan.oelgaard@gmail.com/My Drive/04 Økonomi/10 Thesis/Data/Financials'\n",
    "\n",
    "# read monthly market data from eikon\n",
    "monthly = 'eikon_monthly.xlsx'\n",
    "# daily = 'eikon_daily.xlsx'\n",
    "oxford = 'oxford_economics.xlsx'\n",
    "eikon_dfs = pd.read_excel(path_market + '/' + monthly, sheet_name=None)\n",
    "eikon_keys = eikon_dfs.keys()\n",
    "oxford_df = pd.read_excel(path_market + '/' + oxford)\n",
    "\n",
    "# print(eikon_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "# clean trade data\n",
    "trade_values_df = eikon_dfs['Trade Values'].iloc[:,1:]\n",
    "\n",
    "# set up multi-index for the columns\n",
    "trade_values_df.columns = pd.MultiIndex.from_arrays(trade_values_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "trade_values_df = trade_values_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "trade_values_df.set_index(trade_values_df.columns[0], inplace=True)\n",
    "trade_values_df.index.name = \"Timestamp\"\n",
    "trade_values_df = trade_values_df.sort_index(axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required columns:\n",
    "required_columns = {\"Trade Close\", \"Trade High\", \"Trade Low\", \"Trade Open\", \"Trade Volume\"}\n",
    "\n",
    "# extract all tickers from the first level of the columns\n",
    "tickers = trade_values_df.columns.levels[0]\n",
    "\n",
    "valid_tickers = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    # the sub-columns (second-level) for this particular ticker\n",
    "    subcols = set(trade_values_df[ticker].columns)\n",
    "    \n",
    "    # check if all required columns are present\n",
    "    if required_columns.issubset(subcols):\n",
    "        \n",
    "        # now check how many valid rows the ticker has.\n",
    "        subdf = trade_values_df[ticker][list(required_columns)]\n",
    "        \n",
    "        # count rows that are non-null in *all* required columns:\n",
    "        non_null_rows = subdf.dropna(how=\"any\").shape[0]\n",
    "        \n",
    "        if non_null_rows >= 12: # at least as we uses 12 month momentum\n",
    "            valid_tickers.append(ticker)\n",
    "\n",
    "# filter the original df to keep only valid tickers and all their second-level columns:\n",
    "trade_df = trade_values_df.loc[:, (valid_tickers, slice(None))]\n",
    "\n",
    "# # display or continue working with the cleaned df\n",
    "# display(trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract valid stocks and informtion on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/jsw5n53s1cb1s2q6tt0msrm00000gn/T/ipykernel_46179/3958463826.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stocks_df.rename(columns={'Code': 'Ticker'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# clean stock names\n",
    "stocks_df = eikon_dfs['Unique Stocks'].iloc[:,0:3]\n",
    "# rename Code to Ticker\n",
    "stocks_df.rename(columns={'Code': 'Ticker'}, inplace=True)\n",
    "\n",
    "# use valid_tickers to filter the stocks_df\n",
    "stocks_df = stocks_df[stocks_df['Ticker'].isin(valid_tickers)].reset_index(drop=True)\n",
    "# display(stocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nace_df = eikon_dfs['NACE'].iloc[1:,1:3]\n",
    "\n",
    "# rename columns\n",
    "nace_df.columns = ['Ticker', 'NACE']\n",
    "\n",
    "# identify the NACE codes\n",
    "nace_df['NACE'] = nace_df['NACE'].str.extract(r'\\((\\d+(?:\\.\\d+)?)\\)$')\n",
    "\n",
    "# manually map remaining NACE codes to companies\n",
    "manual_nace = {'CEMAT.CO':'68.20',\n",
    "               'CICC.CO^L01':'70.10',\n",
    "               'DAI.CO^A02':'70.10',\n",
    "               'GR4.CO^A05':'80.10',\n",
    "               'GR4n1.CO^J04':'80.10',\n",
    "               'GR4n2.CO^J04':'80.10',\n",
    "               'IFAC.CO^D03':'64.30',\n",
    "               'INVb.CO^F05':'64.30',\n",
    "               'IPFCa.CO^G02':'70.10',\n",
    "               'IPFCb.CO^G02':'70.10',\n",
    "               'OBJCa.CO^D02':'62.01',\n",
    "               'OBJCb.CO^D02':'62.01',\n",
    "               'ORSTED.CO':'35.11',\n",
    "               'POFLSb.CO^H06':'64.30',\n",
    "               'POKAP.CO^B06':'64.30',\n",
    "               'RADIb.CO^C04':'32.50',\n",
    "               'TRMC.CO^H02':'64.19',\n",
    "               'VEND.CO^C02':'64.19'}\n",
    "\n",
    "for ticker, nace_code in manual_nace.items():\n",
    "    if ticker in nace_df['Ticker'].values:\n",
    "        nace_df.loc[nace_df['Ticker'] == ticker, 'NACE'] = nace_code\n",
    "    else:   \n",
    "        print(f\"Ticker {ticker} not found in NACE DataFrame.\")\n",
    "\n",
    "# split the NACE codes into separate columns\n",
    "nace_df['NACE'] = nace_df['NACE'].str.split('.', expand=True)[0]\n",
    "# nace_df['NACE Industry'] = nace_df['NACE'].str.split('.', expand=True)[0]\n",
    "# nace_df['NACE Sub-industry'] = nace_df['NACE'].str.split('.', expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_df = eikon_dfs['Outstanding Shares'].iloc[:,1:]\n",
    "\n",
    "# make first row the header\n",
    "shares_df.columns = shares_df.iloc[0]\n",
    "shares_df = shares_df[1:]\n",
    "\n",
    "# rename the first column to 'Ticker'\n",
    "shares_df.rename(columns={shares_df.columns[0]: 'Ticker'}, inplace=True)\n",
    "\n",
    "# set columns to type numeric and findf the valid first occurrence\n",
    "shares_df.iloc[:, 1:] = shares_df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "shares_df['Shares'] = shares_df.apply(lambda row: first_valid(row, shares_df.columns[1:]),axis=1)\n",
    "\n",
    "# drop all columns except 'Ticker' and 'Shares'\n",
    "shares_df = shares_df[['Ticker', 'Shares']]\n",
    "\n",
    "# display(shares_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the stocks_df with the nace_df df\n",
    "stocks_df = stocks_df.merge(shares_df, how='left', on='Ticker')\n",
    "stocks_df = stocks_df.merge(nace_df, how='left', on='Ticker')\n",
    "\n",
    "# display(stocks_df)\n",
    "\n",
    "# rename columns\n",
    "stocks_df.rename(columns={\n",
    "    'Ticker': 'ticker',\n",
    "    'Name': 'name',\n",
    "    'Shares': 'shares',\n",
    "    'Code incl. Expiration':'code_incl_expiration',\n",
    "    'NACE': 'NACE',\n",
    "}, inplace=True)\n",
    "\n",
    "# save as stocks\n",
    "stocks_df.to_csv('data/stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing shares for the following tickers:\n",
      "ALBCb.CO^F02: ALBANI BRYG\n",
      "DAI.CO^A02: Dai Holding\n",
      "FRINV.CO^A02: FR INVEST AS\n",
      "IFAC.CO^D03: Regional Invest\n",
      "IPFCa.CO^G02: IPF\n",
      "IPFCb.CO^G02: IPF\n",
      "SAMC.CO^G03: Samson Group\n",
      "TRMC.CO^H02: A/S TARM BANK\n",
      "VEND.CO^C02: Vendsyssel Bank\n"
     ]
    }
   ],
   "source": [
    "# find rows with missing 'shares'\n",
    "missing_shares = stocks_df[stocks_df['shares'].isnull()]\n",
    "# print the tickers with missing shares\n",
    "print(\"Missing shares for the following tickers:\")\n",
    "for ticker in missing_shares['ticker']:\n",
    "    # print ticker and name\n",
    "    name = missing_shares[missing_shares['ticker'] == ticker]['name'].values[0]\n",
    "    print(f\"{ticker}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean P/E, Turnover, Bid, and Ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies with no PE ratio in the entire period: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "pe_ratio_df = eikon_dfs['PE Ratio'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "pe_ratio_df.columns = pd.MultiIndex.from_arrays(pe_ratio_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "pe_ratio_df = pe_ratio_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "pe_ratio_df.set_index(pe_ratio_df.columns[0], inplace=True)\n",
    "pe_ratio_df.index.name = \"Timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "pe_ratio_df = pe_ratio_df.loc[:, (valid_tickers, slice(None))]\n",
    "\n",
    "# rename all the columns called 'PERATIO' to 'PE Ratio'\n",
    "pe_ratio_df.columns = [(ticker, 'PE Ratio') if col == 'PERATIO' else (ticker, col) for ticker, col in pe_ratio_df.columns]\n",
    "\n",
    "# Count columns (tickers) where all values are NaN\n",
    "count_no_pe = pe_ratio_df.isna().all(axis=0).sum()\n",
    "\n",
    "print(f\"Companies with no PE ratio in the entire period: {count_no_pe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "turnover_df = eikon_dfs['Turnover'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "turnover_df.columns = pd.MultiIndex.from_arrays(turnover_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "turnover_df = turnover_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "turnover_df.set_index(turnover_df.columns[0], inplace=True)\n",
    "turnover_df.index.name = \"Timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "turnover_df = turnover_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "ask_df = eikon_dfs['Ask'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "ask_df.columns = pd.MultiIndex.from_arrays(ask_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "ask_df = ask_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "ask_df.set_index(ask_df.columns[0], inplace=True)\n",
    "ask_df.index.name = \"Timestamp\"\n",
    "# filter to only include valid tickers\n",
    "ask_df = ask_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7588: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "bid_df = eikon_dfs['Bid'].iloc[:,1:]\n",
    "\n",
    "# convert the extracted values to strings to prevent dtype inference issues\n",
    "bid_df.columns = pd.MultiIndex.from_arrays(bid_df.iloc[:2].values)\n",
    "\n",
    "# drop the first two rows as they are now headers\n",
    "bid_df = bid_df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# set the first column as index\n",
    "bid_df.set_index(bid_df.columns[0], inplace=True)\n",
    "bid_df.index.name = \"Timestamp\"\n",
    "\n",
    "# filter to only include valid tickers\n",
    "bid_df = bid_df.loc[:, (valid_tickers, slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trade_df.join([pe_ratio_df, turnover_df, ask_df, bid_df],how='outer')\n",
    "\n",
    "# Sort columns by the first level of the multi-index\n",
    "df = df.sort_index(axis=1, level=0)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward fill data if there are gaps in the date range\n",
    "# create an IndexSlice for easier multi-index slicing\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# loop over the tickers that are actually in the df\n",
    "for ticker in df.columns.get_level_values(0).unique():\n",
    "    # extract the sub-dataframe for this ticker using .loc with IndexSlice\n",
    "    subdf = df.loc[:, idx[ticker, :]]\n",
    "    \n",
    "    # find the index range where the ticker has any valid data\n",
    "    valid_idx = subdf.dropna(how='all').index\n",
    "\n",
    "    # use backward fill in the date range\n",
    "    df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]] = df.loc[valid_idx.max():valid_idx.min(), idx[ticker, :]].bfill()\n",
    "\n",
    "# for now, drop all PE Ratios until we get for the remaining ~90 tickers\n",
    "df.drop(columns=[(ticker, 'PE Ratio') for ticker in df.columns.get_level_values(0).unique()], inplace=True)\n",
    "\n",
    "# # display the updated df\n",
    "# display(df)\n",
    "\n",
    "# save df\n",
    "df.to_csv('data/trade.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
